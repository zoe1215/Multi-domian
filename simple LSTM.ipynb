{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogYoSG_MyZpu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a299b8f-7045-4802-9fd6-7da76817636f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN1Mdlvzz7yN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f99227e5-2b6b-46aa-88d7-312e553f87d4"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skCd_ylq0ayy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "0323d791-2d82-480a-87c5-51df89b3be36"
      },
      "source": [
        "# System\n",
        "import os\n",
        "\n",
        "# Time\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "# Numerical\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# NLP\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# from pywsd.utils import lemmatize_sentence\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn import preprocessing\n",
        "from sklearn.utils import class_weight as cw\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Model Selection\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "\n",
        "# Machine Learning Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier, ExtraTreesClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Evaluation Metrics\n",
        "from sklearn import metrics \n",
        "from sklearn.metrics import f1_score, accuracy_score,confusion_matrix,classification_report\n",
        "\n",
        "# Deep Learing Preprocessing - Keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Deep Learning Model - Keras\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.utils import plot_model\n",
        "# Deep Learning Model - Keras - CNN\n",
        "from keras.layers import Conv1D, Conv2D, Convolution1D, MaxPooling1D, SeparableConv1D, SpatialDropout1D, \\\n",
        "    GlobalAvgPool1D, GlobalMaxPool1D, GlobalMaxPooling1D \n",
        "from keras.layers.pooling import _GlobalPooling1D\n",
        "from keras.layers import MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Input, Add, concatenate, Dense, Activation, BatchNormalization, Dropout, Flatten\n",
        "from keras.layers import LeakyReLU, PReLU, Lambda, Multiply\n",
        "# Deep Learning Model - Keras - LSTM\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Bidirectional\n",
        "\n",
        "\n",
        "# Deep Learning Parameters - Keras\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "\n",
        "# Deep Learning Callbacs - Keras\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
        "from keras.layers import MaxPooling3D, GlobalMaxPooling3D, GlobalAveragePooling3D\n",
        "# Visualization\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1AHRch52e00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "books_neg = pd.read_csv(\"/content/drive/My Drive/LSTM/books_negative.csv\")\n",
        "books_pos = pd.read_csv(\"/content/drive/My Drive/LSTM/books_positive.csv\")\n",
        "dvd_neg = pd.read_csv(\"/content/drive/My Drive/LSTM/dvd_negative.csv\")\n",
        "dvd_pos = pd.read_csv(\"/content/drive/My Drive/LSTM/dvd_positive.csv\")\n",
        "ele_neg = pd.read_csv(\"/content/drive/My Drive/LSTM/electronics_negative.csv\")\n",
        "ele_pos = pd.read_csv(\"/content/drive/My Drive/LSTM/electronics_positive.csv\")\n",
        "kit_neg = pd.read_csv(\"/content/drive/My Drive/LSTM/kitchen_negative.csv\")\n",
        "kit_pos = pd.read_csv(\"/content/drive/My Drive/LSTM/kitchen_positive.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhjwoyLi3zT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "books_neg['label'] = 0 \n",
        "books_pos['label'] = 1\n",
        "books = pd.concat([books_neg,books_pos],axis = 0)\n",
        "books['domain'] = 'books'\n",
        "dvd_neg['label'] = 0\n",
        "dvd_pos['label'] = 1\n",
        "dvd = pd.concat([dvd_pos, dvd_neg],axis = 0)\n",
        "dvd['domain'] = 'dvd'\n",
        "ele_neg['label'] = 0\n",
        "ele_pos['label'] = 1\n",
        "ele = pd.concat([ele_neg, ele_pos],axis = 0)\n",
        "ele['domain'] = 'electronics'\n",
        "kit_neg['label'] = 0\n",
        "kit_pos['label'] = 1\n",
        "kit = pd.concat([kit_neg, kit_pos],axis = 0)\n",
        "kit['domain'] = 'kitchen'\n",
        "alldata = pd.concat([books,dvd,ele,kit])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOrHavjx34ax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "books =books.reset_index(drop=True)\n",
        "dvd =dvd.reset_index(drop=True)\n",
        "ele =ele.reset_index(drop=True)\n",
        "kit =kit.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSaXzpH3374p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_books = books['review_text']\n",
        "y_books = books['label']\n",
        "\n",
        "x_dvd = dvd['review_text']\n",
        "y_dvd = dvd['label']\n",
        "\n",
        "x_ele = ele['review_text']\n",
        "y_ele = ele['label']\n",
        "\n",
        "x_kit = kit['review_text']\n",
        "y_kit = kit['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7F9E6vE4BYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_doc(doc):\n",
        "    #split into words\n",
        "    tokens = word_tokenize(doc)\n",
        "    #convert to lower case\n",
        "    tokens = [w.lower() for w in tokens]\n",
        "    #prepare regex for char filtering\n",
        "    re_punc =re.compile('[%s]'% re.escape(string.punctuation))\n",
        "    #remove punctuation\n",
        "    stripped =[re_punc.sub('',w) for w in tokens]\n",
        "    #filter out stop words\n",
        "    #stop_words = set(stopwords.words('english'))\n",
        "    #words =[w for w in words if not w in stop_words]\n",
        "    #remove remaining tokens that are not alphabetic\n",
        "    words = [w for w in stripped if w.isalpha()]\n",
        "    #filter out short tokens\n",
        "    tokens = [word for word in words if len(word)>1]\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAXUJy4V4HXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_books = []\n",
        "for m in range(0,len(x_books)):\n",
        "    X = ''.join(str(i)for i in x_books[m])\n",
        "    te = clean_doc(X)\n",
        "    trainx = \" \".join(te)\n",
        "    text_books.append(trainx)\n",
        "\n",
        "text_dvd = []\n",
        "for m in range(0,len(x_dvd)):\n",
        "    X = ''.join(str(i)for i in x_dvd[m])\n",
        "    te = clean_doc(X)\n",
        "    trainx = \" \".join(te)\n",
        "    text_dvd.append(trainx)\n",
        "\n",
        "\n",
        "text_ele = []\n",
        "for m in range(0,len(x_ele)):\n",
        "    X = ''.join(str(i)for i in x_ele[m])\n",
        "    te = clean_doc(X)\n",
        "    trainx = \" \".join(te)\n",
        "    text_ele.append(trainx)\n",
        "\n",
        "\n",
        "text_kit = []\n",
        "for m in range(0,len(x_kit)):\n",
        "    X = ''.join(str(i)for i in x_kit[m])\n",
        "    te = clean_doc(X)\n",
        "    trainx = \" \".join(te)\n",
        "    text_kit.append(trainx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k35kO6Mi4W5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokens\n",
        "tokens_b = []\n",
        "for m in range(0,len(x_books)):\n",
        "    X = ''.join(str(i)for i in x_books[m])\n",
        "    te = clean_doc(X)\n",
        "    tokens_b.append(te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1VELP_C26gC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define the word2vec model\n",
        "w2v_model = Word2Vec(tokens_b,min_count=1,size=100,workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeplW8yf3LKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert text data to vector\n",
        "x_wv_b=[]\n",
        "for i in range(len(tokens_b)): \n",
        "    vector=w2v_model.wv[tokens_b[i]]\n",
        "    x_wv_b.append(vector)\n",
        "    \n",
        "X_wv_b=np.array(x_wv_b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBrHDops2oGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 120"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvrvN0yv_5mB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61jvUM-91Gxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pad the vectors\n",
        "X_wv_b_padded=pad_sequences(X_wv_b,  maxlen=max_len, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mXFTJpr2Hus",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2ce611ba-bfb2-453e-efa0-75692170aff7"
      },
      "source": [
        "print(X_wv_b.shape)\n",
        "print(X_wv_b_padded.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000,)\n",
            "(2000, 120, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUnRPsYI5Tmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Nerual Embedding Averaging\n",
        "X_wv_b_average=[]\n",
        "for i in X_wv_b:\n",
        "    target_vector=[]\n",
        "    target_vector=np.mean(i, axis=0)\n",
        "    X_wv_b_average.append(target_vector) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG-AbA5f5WsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16930935-2307-42d7-d2f0-ce3291ec89b3"
      },
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "Y_books = label_encoder.fit_transform(y_books)\n",
        "Y_books = to_categorical(Y_books)\n",
        "Y_books.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjMg81w15axm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split to validation and training\n",
        "X_train_b, X_valid_b = X_wv_b_padded[:1700], X_wv_b_padded[1700:]\n",
        "Y_train_b, Y_valid_b = Y_books[:1700], Y_books[1700:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQa-xHBx5em0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the LSTM model\n",
        "def LSTM_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(120,return_sequences=False))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    # summarize defined model\n",
        "    model.build(input_shape=(None,120,100))\n",
        "    model.summary()\n",
        "    plot_model(model, to_file='LSTMmodel.png', show_shapes=True)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPYzzhLf5hAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "fa3a9438-a182-4df6-cf73-db0a636158b7"
      },
      "source": [
        "model_LSTM = LSTM_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 120)               106080    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 242       \n",
            "=================================================================\n",
            "Total params: 106,322\n",
            "Trainable params: 106,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppoLx1AT5kYp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4bc61341-adf9-44ba-9d0a-f50faa0e8ad1"
      },
      "source": [
        "# fit network\n",
        "history = model_LSTM.fit(X_train_b, Y_train_b, validation_data=(X_valid_b, Y_valid_b),batch_size=128,epochs=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1700 samples, validate on 300 samples\n",
            "Epoch 1/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.4660 - accuracy: 0.7706 - val_loss: 0.9613 - val_accuracy: 0.5433\n",
            "Epoch 2/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 1.3971 - val_accuracy: 0.2867\n",
            "Epoch 3/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.4325 - accuracy: 0.7835 - val_loss: 1.3119 - val_accuracy: 0.3400\n",
            "Epoch 4/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.4170 - accuracy: 0.7947 - val_loss: 1.2440 - val_accuracy: 0.4400\n",
            "Epoch 5/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.4101 - accuracy: 0.8059 - val_loss: 1.2204 - val_accuracy: 0.4900\n",
            "Epoch 6/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.3875 - accuracy: 0.8194 - val_loss: 1.2926 - val_accuracy: 0.4900\n",
            "Epoch 7/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.3623 - accuracy: 0.8288 - val_loss: 1.3725 - val_accuracy: 0.5167\n",
            "Epoch 8/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.3568 - accuracy: 0.8341 - val_loss: 1.5123 - val_accuracy: 0.4633\n",
            "Epoch 9/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.3464 - accuracy: 0.8318 - val_loss: 1.5560 - val_accuracy: 0.5000\n",
            "Epoch 10/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.3426 - accuracy: 0.8347 - val_loss: 1.6264 - val_accuracy: 0.4467\n",
            "Epoch 11/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.3106 - accuracy: 0.8618 - val_loss: 1.3355 - val_accuracy: 0.5667\n",
            "Epoch 12/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.3147 - accuracy: 0.8624 - val_loss: 1.4343 - val_accuracy: 0.5533\n",
            "Epoch 13/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.3103 - accuracy: 0.8641 - val_loss: 1.4532 - val_accuracy: 0.5333\n",
            "Epoch 14/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.3341 - accuracy: 0.8441 - val_loss: 1.4411 - val_accuracy: 0.4367\n",
            "Epoch 15/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.3281 - accuracy: 0.8494 - val_loss: 1.5309 - val_accuracy: 0.4867\n",
            "Epoch 16/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.3168 - accuracy: 0.8618 - val_loss: 1.3549 - val_accuracy: 0.5033\n",
            "Epoch 17/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.2921 - accuracy: 0.8706 - val_loss: 1.5724 - val_accuracy: 0.4900\n",
            "Epoch 18/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.2627 - accuracy: 0.8818 - val_loss: 1.4764 - val_accuracy: 0.5600\n",
            "Epoch 19/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.2995 - accuracy: 0.8671 - val_loss: 1.8300 - val_accuracy: 0.4000\n",
            "Epoch 20/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.2730 - accuracy: 0.8859 - val_loss: 1.5252 - val_accuracy: 0.4933\n",
            "Epoch 21/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.2507 - accuracy: 0.8971 - val_loss: 1.2278 - val_accuracy: 0.6667\n",
            "Epoch 22/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.2733 - accuracy: 0.8765 - val_loss: 1.8541 - val_accuracy: 0.4367\n",
            "Epoch 23/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.2538 - accuracy: 0.8912 - val_loss: 1.5503 - val_accuracy: 0.5600\n",
            "Epoch 24/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.2652 - accuracy: 0.8829 - val_loss: 1.5932 - val_accuracy: 0.5267\n",
            "Epoch 25/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.2274 - accuracy: 0.9071 - val_loss: 1.9983 - val_accuracy: 0.4333\n",
            "Epoch 26/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.2136 - accuracy: 0.9176 - val_loss: 1.6814 - val_accuracy: 0.5100\n",
            "Epoch 27/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1897 - accuracy: 0.9300 - val_loss: 1.7861 - val_accuracy: 0.5367\n",
            "Epoch 28/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1861 - accuracy: 0.9318 - val_loss: 1.7677 - val_accuracy: 0.5267\n",
            "Epoch 29/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.2021 - accuracy: 0.9188 - val_loss: 1.7694 - val_accuracy: 0.4967\n",
            "Epoch 30/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1928 - accuracy: 0.9259 - val_loss: 2.1271 - val_accuracy: 0.5000\n",
            "Epoch 31/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1857 - accuracy: 0.9312 - val_loss: 1.6642 - val_accuracy: 0.5667\n",
            "Epoch 32/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1780 - accuracy: 0.9359 - val_loss: 1.9329 - val_accuracy: 0.4833\n",
            "Epoch 33/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1583 - accuracy: 0.9453 - val_loss: 2.3630 - val_accuracy: 0.4333\n",
            "Epoch 34/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1800 - accuracy: 0.9282 - val_loss: 1.9347 - val_accuracy: 0.5100\n",
            "Epoch 35/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1763 - accuracy: 0.9318 - val_loss: 1.8995 - val_accuracy: 0.5367\n",
            "Epoch 36/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.2333 - accuracy: 0.9035 - val_loss: 1.7119 - val_accuracy: 0.4867\n",
            "Epoch 37/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1799 - accuracy: 0.9318 - val_loss: 1.8175 - val_accuracy: 0.5033\n",
            "Epoch 38/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1865 - accuracy: 0.9318 - val_loss: 2.1292 - val_accuracy: 0.4767\n",
            "Epoch 39/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1761 - accuracy: 0.9388 - val_loss: 1.9070 - val_accuracy: 0.4400\n",
            "Epoch 40/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1448 - accuracy: 0.9488 - val_loss: 2.1898 - val_accuracy: 0.4333\n",
            "Epoch 41/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1271 - accuracy: 0.9518 - val_loss: 2.5606 - val_accuracy: 0.3733\n",
            "Epoch 42/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1746 - accuracy: 0.9353 - val_loss: 2.4157 - val_accuracy: 0.3867\n",
            "Epoch 43/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1418 - accuracy: 0.9506 - val_loss: 2.9027 - val_accuracy: 0.3467\n",
            "Epoch 44/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1565 - accuracy: 0.9418 - val_loss: 1.8114 - val_accuracy: 0.5000\n",
            "Epoch 45/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1206 - accuracy: 0.9635 - val_loss: 2.0074 - val_accuracy: 0.5033\n",
            "Epoch 46/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1121 - accuracy: 0.9659 - val_loss: 2.5196 - val_accuracy: 0.3967\n",
            "Epoch 47/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.2586 - accuracy: 0.8953 - val_loss: 1.8106 - val_accuracy: 0.4400\n",
            "Epoch 48/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1943 - accuracy: 0.9294 - val_loss: 1.6991 - val_accuracy: 0.5067\n",
            "Epoch 49/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1634 - accuracy: 0.9412 - val_loss: 1.9885 - val_accuracy: 0.5133\n",
            "Epoch 50/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1267 - accuracy: 0.9535 - val_loss: 2.4226 - val_accuracy: 0.3567\n",
            "Epoch 51/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1754 - accuracy: 0.9376 - val_loss: 2.5270 - val_accuracy: 0.3633\n",
            "Epoch 52/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1530 - accuracy: 0.9441 - val_loss: 2.1264 - val_accuracy: 0.4467\n",
            "Epoch 53/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1265 - accuracy: 0.9588 - val_loss: 1.8921 - val_accuracy: 0.5500\n",
            "Epoch 54/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1203 - accuracy: 0.9635 - val_loss: 1.9755 - val_accuracy: 0.5300\n",
            "Epoch 55/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1727 - accuracy: 0.9347 - val_loss: 1.9855 - val_accuracy: 0.4967\n",
            "Epoch 56/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1649 - accuracy: 0.9441 - val_loss: 2.2552 - val_accuracy: 0.4133\n",
            "Epoch 57/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1350 - accuracy: 0.9565 - val_loss: 2.4067 - val_accuracy: 0.4367\n",
            "Epoch 58/200\n",
            "1700/1700 [==============================] - 7s 4ms/step - loss: 0.0889 - accuracy: 0.9753 - val_loss: 2.3148 - val_accuracy: 0.4933\n",
            "Epoch 59/200\n",
            "1700/1700 [==============================] - 7s 4ms/step - loss: 0.0751 - accuracy: 0.9765 - val_loss: 2.2781 - val_accuracy: 0.5200\n",
            "Epoch 60/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1127 - accuracy: 0.9629 - val_loss: 2.1453 - val_accuracy: 0.5467\n",
            "Epoch 61/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1012 - accuracy: 0.9641 - val_loss: 2.3810 - val_accuracy: 0.4833\n",
            "Epoch 62/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0781 - accuracy: 0.9771 - val_loss: 2.5100 - val_accuracy: 0.4700\n",
            "Epoch 63/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0712 - accuracy: 0.9788 - val_loss: 2.3926 - val_accuracy: 0.4800\n",
            "Epoch 64/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1186 - accuracy: 0.9594 - val_loss: 2.7250 - val_accuracy: 0.3933\n",
            "Epoch 65/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1125 - accuracy: 0.9647 - val_loss: 2.8742 - val_accuracy: 0.3167\n",
            "Epoch 66/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0817 - accuracy: 0.9753 - val_loss: 2.4854 - val_accuracy: 0.4467\n",
            "Epoch 67/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0651 - accuracy: 0.9794 - val_loss: 2.4043 - val_accuracy: 0.4467\n",
            "Epoch 68/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0665 - accuracy: 0.9794 - val_loss: 2.8950 - val_accuracy: 0.3900\n",
            "Epoch 69/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0800 - accuracy: 0.9706 - val_loss: 2.4768 - val_accuracy: 0.4567\n",
            "Epoch 70/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1167 - accuracy: 0.9582 - val_loss: 2.3406 - val_accuracy: 0.4667\n",
            "Epoch 71/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1037 - accuracy: 0.9665 - val_loss: 2.3785 - val_accuracy: 0.4867\n",
            "Epoch 72/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0903 - accuracy: 0.9712 - val_loss: 2.7098 - val_accuracy: 0.4033\n",
            "Epoch 73/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0610 - accuracy: 0.9812 - val_loss: 3.0968 - val_accuracy: 0.3533\n",
            "Epoch 74/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1308 - accuracy: 0.9535 - val_loss: 3.2219 - val_accuracy: 0.3433\n",
            "Epoch 75/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1315 - accuracy: 0.9524 - val_loss: 2.5365 - val_accuracy: 0.4300\n",
            "Epoch 76/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0990 - accuracy: 0.9712 - val_loss: 2.0231 - val_accuracy: 0.5267\n",
            "Epoch 77/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0680 - accuracy: 0.9765 - val_loss: 2.8121 - val_accuracy: 0.4500\n",
            "Epoch 78/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0473 - accuracy: 0.9835 - val_loss: 2.8896 - val_accuracy: 0.4567\n",
            "Epoch 79/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0529 - accuracy: 0.9841 - val_loss: 3.2258 - val_accuracy: 0.4333\n",
            "Epoch 80/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1538 - accuracy: 0.9465 - val_loss: 2.4574 - val_accuracy: 0.4967\n",
            "Epoch 81/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.2357 - accuracy: 0.9153 - val_loss: 2.4033 - val_accuracy: 0.3867\n",
            "Epoch 82/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1391 - accuracy: 0.9535 - val_loss: 2.1789 - val_accuracy: 0.4867\n",
            "Epoch 83/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1222 - accuracy: 0.9571 - val_loss: 2.0559 - val_accuracy: 0.5133\n",
            "Epoch 84/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1087 - accuracy: 0.9618 - val_loss: 2.4321 - val_accuracy: 0.4633\n",
            "Epoch 85/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0801 - accuracy: 0.9747 - val_loss: 2.3351 - val_accuracy: 0.5100\n",
            "Epoch 86/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0741 - accuracy: 0.9747 - val_loss: 3.0802 - val_accuracy: 0.4033\n",
            "Epoch 87/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0462 - accuracy: 0.9824 - val_loss: 2.7340 - val_accuracy: 0.4567\n",
            "Epoch 88/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0618 - accuracy: 0.9818 - val_loss: 2.8129 - val_accuracy: 0.4767\n",
            "Epoch 89/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0629 - accuracy: 0.9806 - val_loss: 2.9545 - val_accuracy: 0.4633\n",
            "Epoch 90/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0542 - accuracy: 0.9800 - val_loss: 2.8278 - val_accuracy: 0.4900\n",
            "Epoch 91/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0369 - accuracy: 0.9871 - val_loss: 2.8858 - val_accuracy: 0.4900\n",
            "Epoch 92/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0412 - accuracy: 0.9859 - val_loss: 2.9915 - val_accuracy: 0.4867\n",
            "Epoch 93/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0368 - accuracy: 0.9871 - val_loss: 2.9286 - val_accuracy: 0.4933\n",
            "Epoch 94/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0856 - accuracy: 0.9700 - val_loss: 1.9737 - val_accuracy: 0.5633\n",
            "Epoch 95/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.3592 - accuracy: 0.8529 - val_loss: 1.8884 - val_accuracy: 0.3200\n",
            "Epoch 96/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.2378 - accuracy: 0.8912 - val_loss: 1.9822 - val_accuracy: 0.5033\n",
            "Epoch 97/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1503 - accuracy: 0.9441 - val_loss: 2.2844 - val_accuracy: 0.4367\n",
            "Epoch 98/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1527 - accuracy: 0.9547 - val_loss: 2.2028 - val_accuracy: 0.5167\n",
            "Epoch 99/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.2047 - accuracy: 0.9259 - val_loss: 1.9075 - val_accuracy: 0.4233\n",
            "Epoch 100/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1609 - accuracy: 0.9488 - val_loss: 1.9806 - val_accuracy: 0.4900\n",
            "Epoch 101/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1038 - accuracy: 0.9682 - val_loss: 2.0961 - val_accuracy: 0.5433\n",
            "Epoch 102/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0755 - accuracy: 0.9753 - val_loss: 2.7735 - val_accuracy: 0.4133\n",
            "Epoch 103/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0677 - accuracy: 0.9753 - val_loss: 1.7190 - val_accuracy: 0.6333\n",
            "Epoch 104/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1129 - accuracy: 0.9594 - val_loss: 2.2858 - val_accuracy: 0.5267\n",
            "Epoch 105/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0729 - accuracy: 0.9753 - val_loss: 3.0458 - val_accuracy: 0.3733\n",
            "Epoch 106/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0399 - accuracy: 0.9882 - val_loss: 2.7903 - val_accuracy: 0.4267\n",
            "Epoch 107/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0403 - accuracy: 0.9865 - val_loss: 2.9279 - val_accuracy: 0.4167\n",
            "Epoch 108/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0395 - accuracy: 0.9894 - val_loss: 2.9324 - val_accuracy: 0.4433\n",
            "Epoch 109/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0550 - accuracy: 0.9841 - val_loss: 3.9956 - val_accuracy: 0.2967\n",
            "Epoch 110/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1350 - accuracy: 0.9559 - val_loss: 2.5330 - val_accuracy: 0.4200\n",
            "Epoch 111/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0693 - accuracy: 0.9788 - val_loss: 2.5961 - val_accuracy: 0.4400\n",
            "Epoch 112/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0441 - accuracy: 0.9865 - val_loss: 3.0245 - val_accuracy: 0.4133\n",
            "Epoch 113/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0269 - accuracy: 0.9929 - val_loss: 3.0064 - val_accuracy: 0.4300\n",
            "Epoch 114/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0190 - accuracy: 0.9959 - val_loss: 3.1390 - val_accuracy: 0.4200\n",
            "Epoch 115/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0269 - accuracy: 0.9929 - val_loss: 2.7893 - val_accuracy: 0.4867\n",
            "Epoch 116/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1089 - accuracy: 0.9676 - val_loss: 2.9211 - val_accuracy: 0.4033\n",
            "Epoch 117/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1115 - accuracy: 0.9635 - val_loss: 2.7956 - val_accuracy: 0.3867\n",
            "Epoch 118/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0769 - accuracy: 0.9741 - val_loss: 2.4407 - val_accuracy: 0.4767\n",
            "Epoch 119/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0382 - accuracy: 0.9900 - val_loss: 2.8388 - val_accuracy: 0.4367\n",
            "Epoch 120/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0166 - accuracy: 0.9965 - val_loss: 3.1212 - val_accuracy: 0.4133\n",
            "Epoch 121/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0105 - accuracy: 0.9982 - val_loss: 2.9572 - val_accuracy: 0.4533\n",
            "Epoch 122/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0097 - accuracy: 0.9988 - val_loss: 3.0423 - val_accuracy: 0.4500\n",
            "Epoch 123/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0076 - accuracy: 0.9994 - val_loss: 3.1136 - val_accuracy: 0.4533\n",
            "Epoch 124/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 3.4175 - val_accuracy: 0.4367\n",
            "Epoch 125/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 3.4732 - val_accuracy: 0.4133\n",
            "Epoch 126/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0091 - accuracy: 0.9965 - val_loss: 3.2383 - val_accuracy: 0.4667\n",
            "Epoch 127/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0150 - accuracy: 0.9971 - val_loss: 3.3731 - val_accuracy: 0.4567\n",
            "Epoch 128/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 3.4824 - val_accuracy: 0.4500\n",
            "Epoch 129/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 3.4812 - val_accuracy: 0.4400\n",
            "Epoch 130/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 3.5519 - val_accuracy: 0.4233\n",
            "Epoch 131/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 3.7471 - val_accuracy: 0.4033\n",
            "Epoch 132/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0118 - accuracy: 0.9971 - val_loss: 3.9969 - val_accuracy: 0.3867\n",
            "Epoch 133/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 4.0535 - val_accuracy: 0.3767\n",
            "Epoch 134/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0402 - accuracy: 0.9882 - val_loss: 3.6471 - val_accuracy: 0.4500\n",
            "Epoch 135/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0551 - accuracy: 0.9788 - val_loss: 2.8832 - val_accuracy: 0.4567\n",
            "Epoch 136/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0851 - accuracy: 0.9729 - val_loss: 3.5347 - val_accuracy: 0.3267\n",
            "Epoch 137/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0816 - accuracy: 0.9753 - val_loss: 2.3104 - val_accuracy: 0.5467\n",
            "Epoch 138/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0551 - accuracy: 0.9812 - val_loss: 2.8789 - val_accuracy: 0.4533\n",
            "Epoch 139/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0287 - accuracy: 0.9918 - val_loss: 3.2220 - val_accuracy: 0.4200\n",
            "Epoch 140/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0137 - accuracy: 0.9971 - val_loss: 3.1576 - val_accuracy: 0.4533\n",
            "Epoch 141/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0101 - accuracy: 0.9982 - val_loss: 3.6188 - val_accuracy: 0.4033\n",
            "Epoch 142/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 3.5554 - val_accuracy: 0.4333\n",
            "Epoch 143/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 3.4649 - val_accuracy: 0.4533\n",
            "Epoch 144/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 3.6268 - val_accuracy: 0.4267\n",
            "Epoch 145/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 3.5902 - val_accuracy: 0.4333\n",
            "Epoch 146/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 3.3789 - val_accuracy: 0.4567\n",
            "Epoch 147/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0060 - accuracy: 0.9994 - val_loss: 3.0223 - val_accuracy: 0.5067\n",
            "Epoch 148/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1051 - accuracy: 0.9700 - val_loss: 2.1337 - val_accuracy: 0.6500\n",
            "Epoch 149/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.6592 - accuracy: 0.7982 - val_loss: 1.5506 - val_accuracy: 0.4167\n",
            "Epoch 150/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.4400 - accuracy: 0.8171 - val_loss: 1.3489 - val_accuracy: 0.4000\n",
            "Epoch 151/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.3477 - accuracy: 0.8435 - val_loss: 1.3990 - val_accuracy: 0.4000\n",
            "Epoch 152/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.2688 - accuracy: 0.8935 - val_loss: 1.4291 - val_accuracy: 0.5433\n",
            "Epoch 153/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.2068 - accuracy: 0.9235 - val_loss: 1.4289 - val_accuracy: 0.6000\n",
            "Epoch 154/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1515 - accuracy: 0.9512 - val_loss: 1.8248 - val_accuracy: 0.5000\n",
            "Epoch 155/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1107 - accuracy: 0.9659 - val_loss: 2.2776 - val_accuracy: 0.4300\n",
            "Epoch 156/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0857 - accuracy: 0.9735 - val_loss: 2.4163 - val_accuracy: 0.4600\n",
            "Epoch 157/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1079 - accuracy: 0.9612 - val_loss: 2.6359 - val_accuracy: 0.4133\n",
            "Epoch 158/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0847 - accuracy: 0.9700 - val_loss: 2.5122 - val_accuracy: 0.4367\n",
            "Epoch 159/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0697 - accuracy: 0.9812 - val_loss: 2.6482 - val_accuracy: 0.4433\n",
            "Epoch 160/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0608 - accuracy: 0.9812 - val_loss: 2.5610 - val_accuracy: 0.4833\n",
            "Epoch 161/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0427 - accuracy: 0.9841 - val_loss: 2.8004 - val_accuracy: 0.4500\n",
            "Epoch 162/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0284 - accuracy: 0.9894 - val_loss: 2.9077 - val_accuracy: 0.4700\n",
            "Epoch 163/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0283 - accuracy: 0.9894 - val_loss: 2.9806 - val_accuracy: 0.4467\n",
            "Epoch 164/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0343 - accuracy: 0.9876 - val_loss: 2.9060 - val_accuracy: 0.4733\n",
            "Epoch 165/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0230 - accuracy: 0.9918 - val_loss: 3.4366 - val_accuracy: 0.3867\n",
            "Epoch 166/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0184 - accuracy: 0.9947 - val_loss: 3.3350 - val_accuracy: 0.4233\n",
            "Epoch 167/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0191 - accuracy: 0.9947 - val_loss: 3.4086 - val_accuracy: 0.4400\n",
            "Epoch 168/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0309 - accuracy: 0.9906 - val_loss: 3.1928 - val_accuracy: 0.4567\n",
            "Epoch 169/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0241 - accuracy: 0.9918 - val_loss: 3.9179 - val_accuracy: 0.3367\n",
            "Epoch 170/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1103 - accuracy: 0.9594 - val_loss: 2.7079 - val_accuracy: 0.4467\n",
            "Epoch 171/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0816 - accuracy: 0.9724 - val_loss: 2.5474 - val_accuracy: 0.4500\n",
            "Epoch 172/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0770 - accuracy: 0.9729 - val_loss: 2.0749 - val_accuracy: 0.5433\n",
            "Epoch 173/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.1663 - accuracy: 0.9429 - val_loss: 3.0301 - val_accuracy: 0.3467\n",
            "Epoch 174/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1577 - accuracy: 0.9494 - val_loss: 2.1610 - val_accuracy: 0.4367\n",
            "Epoch 175/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.1335 - accuracy: 0.9524 - val_loss: 2.3392 - val_accuracy: 0.4267\n",
            "Epoch 176/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0736 - accuracy: 0.9741 - val_loss: 2.4167 - val_accuracy: 0.4733\n",
            "Epoch 177/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0327 - accuracy: 0.9912 - val_loss: 2.7865 - val_accuracy: 0.4267\n",
            "Epoch 178/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0246 - accuracy: 0.9900 - val_loss: 2.8680 - val_accuracy: 0.4467\n",
            "Epoch 179/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0158 - accuracy: 0.9941 - val_loss: 3.0759 - val_accuracy: 0.4167\n",
            "Epoch 180/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0110 - accuracy: 0.9982 - val_loss: 3.1997 - val_accuracy: 0.4167\n",
            "Epoch 181/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 3.1117 - val_accuracy: 0.4400\n",
            "Epoch 182/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 3.1294 - val_accuracy: 0.4600\n",
            "Epoch 183/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 3.2002 - val_accuracy: 0.4433\n",
            "Epoch 184/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0081 - accuracy: 0.9988 - val_loss: 3.2036 - val_accuracy: 0.4400\n",
            "Epoch 185/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 3.2198 - val_accuracy: 0.4433\n",
            "Epoch 186/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.3727 - val_accuracy: 0.4500\n",
            "Epoch 187/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.4451 - val_accuracy: 0.4333\n",
            "Epoch 188/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.4260 - val_accuracy: 0.4367\n",
            "Epoch 189/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.4151 - val_accuracy: 0.4367\n",
            "Epoch 190/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.4207 - val_accuracy: 0.4467\n",
            "Epoch 191/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.4340 - val_accuracy: 0.4467\n",
            "Epoch 192/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.4639 - val_accuracy: 0.4500\n",
            "Epoch 193/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.4822 - val_accuracy: 0.4467\n",
            "Epoch 194/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 9.5092e-04 - accuracy: 1.0000 - val_loss: 3.4999 - val_accuracy: 0.4467\n",
            "Epoch 195/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 9.0320e-04 - accuracy: 1.0000 - val_loss: 3.5190 - val_accuracy: 0.4467\n",
            "Epoch 196/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 8.5790e-04 - accuracy: 1.0000 - val_loss: 3.5377 - val_accuracy: 0.4433\n",
            "Epoch 197/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 8.1758e-04 - accuracy: 1.0000 - val_loss: 3.5516 - val_accuracy: 0.4433\n",
            "Epoch 198/200\n",
            "1700/1700 [==============================] - 6s 3ms/step - loss: 7.8242e-04 - accuracy: 1.0000 - val_loss: 3.5762 - val_accuracy: 0.4333\n",
            "Epoch 199/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 7.4960e-04 - accuracy: 1.0000 - val_loss: 3.5849 - val_accuracy: 0.4333\n",
            "Epoch 200/200\n",
            "1700/1700 [==============================] - 6s 4ms/step - loss: 7.1894e-04 - accuracy: 1.0000 - val_loss: 3.6037 - val_accuracy: 0.4333\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}