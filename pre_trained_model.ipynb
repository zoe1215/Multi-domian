{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pre-trained model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA8XlaXxqJlP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4751f77-2bbd-4f06-e303-c1c157ceece5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgU5XN5XEZ44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de522f62-53f6-42f0-ecd0-18b87dca73ba"
      },
      "source": [
        "pip install mxnet"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.6/dist-packages (1.6.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.18.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TryhZSB8Ez-o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "80c1361a-67f7-477c-aafa-2ff4f8858b37"
      },
      "source": [
        "pip install gluonnlp"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gluonnlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/27/07b57d22496ed6c98b247e578712122402487f5c265ec70a747900f97060/gluonnlp-0.9.1.tar.gz (252kB)\n",
            "\r\u001b[K     |█▎                              | 10kB 19.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (1.18.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (0.29.21)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (20.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.9.1-cp36-cp36m-linux_x86_64.whl size=470038 sha256=be14c3b7c6a200b7020a54469092f3de4985f96ed3d1134ba2cd65cbe1bf1c58\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/60/16/1f8a40e68b85bd9bd7960e91830bca5e40cd113f3220b7e231\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8zlHfdBJ6rT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8e3f2414-2285-4281-94c0-30cfc83ed400"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0dcgws7DbES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# NLP\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import random\n",
        "import time\n",
        "import multiprocessing as mp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import mxnet as mx\n",
        "from mxnet import nd, gluon, autograd\n",
        "\n",
        "import gluonnlp as nlp\n",
        "nlp.utils.check_version('0.7.0')\n",
        "\n",
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "mx.random.seed(123)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG60cvDtItxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MeanPoolingLayer(gluon.HybridBlock):\n",
        "    \"\"\"A block for mean pooling of encoder features\"\"\"\n",
        "    def __init__(self, prefix=None, params=None):\n",
        "        super(MeanPoolingLayer, self).__init__(prefix=prefix, params=params)\n",
        "\n",
        "    def hybrid_forward(self, F, data, valid_length): # pylint: disable=arguments-differ\n",
        "        \"\"\"Forward logic\"\"\"\n",
        "        # Data will have shape (T, N, C)\n",
        "        masked_encoded = F.SequenceMask(data,\n",
        "                                        sequence_length=valid_length,\n",
        "                                        use_sequence_length=True)\n",
        "        agg_state = F.broadcast_div(F.sum(masked_encoded, axis=0),\n",
        "                                    F.expand_dims(valid_length, axis=1))\n",
        "        return agg_state\n",
        "\n",
        "\n",
        "class SentimentNet(gluon.HybridBlock):\n",
        "    \"\"\"Network for sentiment analysis.\"\"\"\n",
        "    def __init__(self, dropout, prefix=None, params=None):\n",
        "        super(SentimentNet, self).__init__(prefix=prefix, params=params)\n",
        "        with self.name_scope():\n",
        "            self.embedding = None # will set with lm embedding later\n",
        "            self.encoder = None # will set with lm encoder later\n",
        "            self.agg_layer = MeanPoolingLayer()\n",
        "            self.output = gluon.nn.HybridSequential()\n",
        "            with self.output.name_scope():\n",
        "                self.output.add(gluon.nn.Dropout(dropout))\n",
        "                self.output.add(gluon.nn.Dense(1, flatten=False))\n",
        "\n",
        "    def hybrid_forward(self, F, data, valid_length): # pylint: disable=arguments-differ\n",
        "        encoded = self.encoder(self.embedding(data))  # Shape(T, N, C)\n",
        "        agg_state = self.agg_layer(encoded, valid_length)\n",
        "        out = self.output(agg_state)\n",
        "        return out"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WcHjBGkJM4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout = 0\n",
        "language_model_name = 'standard_lstm_lm_200'\n",
        "pretrained = True\n",
        "learning_rate, batch_size = 0.005, 32\n",
        "bucket_num, bucket_ratio = 10, 0.2\n",
        "epochs = 100\n",
        "grad_clip = None\n",
        "log_interval = 100"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t67uug77JpSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context = mx.cpu()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUdSb5UHJ4JE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c1f6d393-9094-4035-8aa4-357bf32786cf"
      },
      "source": [
        "lm_model, vocab = nlp.model.get_model(name=language_model_name,\n",
        "                                      dataset_name='wikitext-2',\n",
        "                                      pretrained=pretrained,\n",
        "                                      ctx=context,\n",
        "                                      dropout=dropout)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab file is not found. Downloading.\n",
            "Downloading /root/.mxnet/models/7729646630986104513/7729646630986104513_wikitext-2-be36dc52.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/vocab/wikitext-2-be36dc52.zip...\n",
            "Downloading /root/.mxnet/models/standard_lstm_lm_200_wikitext-2-b233c700.zip75b98200-d0bf-4093-9689-adef852f4369 from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/standard_lstm_lm_200_wikitext-2-b233c700.zip...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqxK18jHY_NE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "cbe898bd-cadb-479f-93ab-e389d8c5c4db"
      },
      "source": [
        "net = SentimentNet(dropout=dropout)\n",
        "net.embedding = lm_model.embedding\n",
        "net.encoder = lm_model.encoder\n",
        "net.hybridize()\n",
        "net.output.initialize(mx.init.Xavier(), ctx=context)\n",
        "                      \n",
        "print(net)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentNet(\n",
            "  (embedding): HybridSequential(\n",
            "    (0): Embedding(33278 -> 200, float32)\n",
            "  )\n",
            "  (encoder): LSTM(200 -> 200, TNC, num_layers=2)\n",
            "  (agg_layer): MeanPoolingLayer(\n",
            "  \n",
            "  )\n",
            "  (output): HybridSequential(\n",
            "    (0): Dropout(p = 0, axes=())\n",
            "    (1): Dense(None -> 1, linear)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zVYgzHCaX2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The tokenizer takes as input a string and outputs a list of tokens.\n",
        "tokenizer = nlp.data.SpacyTokenizer('en')\n",
        "\n",
        "# `length_clip` takes as input a list and outputs a list with maximum length 120.\n",
        "length_clip = nlp.data.ClipSequence(120)\n",
        "\n",
        "# Helper function to preprocess a single data point\n",
        "def preprocess(x):\n",
        "    data, label = x\n",
        "    data = vocab[length_clip(tokenizer(data))]\n",
        "    lengths = float(len(x[0]))\n",
        "    return data, label\n",
        "\n",
        "# Helper function for getting the length\n",
        "def get_length(x):\n",
        "    return float(len(x[0]))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocVlFPvxdzWS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86083696-8371-4433-9a59-c052e1aa06ca"
      },
      "source": [
        "# Loading the dataset\n",
        "books_neg = pd.read_csv(\"/content/drive/My Drive/LSTM/books_negative.csv\")\n",
        "books_pos = pd.read_csv(\"/content/drive/My Drive/LSTM/books_positive.csv\")\n",
        "dvd_neg = pd.read_csv(\"/content/drive/My Drive/LSTM/dvd_negative.csv\")\n",
        "dvd_pos = pd.read_csv(\"/content/drive/My Drive/LSTM/dvd_positive.csv\")\n",
        "ele_neg = pd.read_csv(\"/content/drive/My Drive/LSTM/electronics_negative.csv\")\n",
        "ele_pos = pd.read_csv(\"/content/drive/My Drive/LSTM/electronics_positive.csv\")\n",
        "kit_neg = pd.read_csv(\"/content/drive/My Drive/LSTM/kitchen_negative.csv\")\n",
        "kit_pos = pd.read_csv(\"/content/drive/My Drive/LSTM/kitchen_positive.csv\")\n",
        "books_neg['label'] = 0 \n",
        "books_pos['label'] = 1\n",
        "books = pd.concat([books_neg,books_pos],axis = 0)\n",
        "books['domain'] = 'books'\n",
        "dvd_neg['label'] = 0\n",
        "dvd_pos['label'] = 1\n",
        "dvd = pd.concat([dvd_pos, dvd_neg],axis = 0)\n",
        "dvd['domain'] = 'dvd'\n",
        "ele_neg['label'] = 0\n",
        "ele_pos['label'] = 1\n",
        "ele = pd.concat([ele_neg, ele_pos],axis = 0)\n",
        "ele['domain'] = 'electronics'\n",
        "kit_neg['label'] = 0\n",
        "kit_pos['label'] = 1\n",
        "kit = pd.concat([kit_neg, kit_pos],axis = 0)\n",
        "kit['domain'] = 'kitchen'\n",
        "\n",
        "books =books.reset_index(drop=True)\n",
        "dvd =dvd.reset_index(drop=True)\n",
        "ele =ele.reset_index(drop=True)\n",
        "kit =kit.reset_index(drop=True)\n",
        "print('Tokenize using spaCy...')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenize using spaCy...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6HQjECqd3uk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_books = books['review_text']\n",
        "y_books = books['label']\n",
        "\n",
        "x_dvd = dvd['review_text']\n",
        "y_dvd = dvd['label']\n",
        "\n",
        "x_ele = ele['review_text']\n",
        "y_ele = ele['label']\n",
        "\n",
        "x_kit = kit['review_text']\n",
        "y_kit = kit['label']"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-i6VAuJdPMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_dataset(dataset):\n",
        "    start = time.time()\n",
        "    with mp.Pool() as pool:\n",
        "        # Each sample is processed in an asynchronous manner.\n",
        "        dataset = gluon.data.SimpleDataset(pool.map(preprocess, dataset))\n",
        "        lengths = gluon.data.SimpleDataset(pool.map(get_length, dataset))\n",
        "    end = time.time()\n",
        "    print('Done! Tokenizing Time={:.2f}s, #Sentences={}'.format(end - start, len(dataset)))\n",
        "    return dataset, lengths\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY14mHTsUK1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dat_books = []\n",
        "for i in range(0,len(x_books)):\n",
        "  Y = []\n",
        "  Y.append(x_books[i])\n",
        "  Y.append(y_books[i])\n",
        "  dat_books.append(Y)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ky3AjGfZl9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dat_dvd = []\n",
        "for i in range(0,len(x_dvd)):\n",
        "  Y = []\n",
        "  Y.append(x_dvd[i])\n",
        "  Y.append(y_dvd[i])\n",
        "  dat_dvd.append(Y)\n",
        "\n",
        "dat_ele = []\n",
        "for i in range(0,len(x_ele)):\n",
        "  Y = []\n",
        "  Y.append(x_ele[i])\n",
        "  Y.append(y_ele[i])\n",
        "  dat_ele.append(Y)\n",
        "\n",
        "dat_kit = []\n",
        "for i in range(0,len(x_kit)):\n",
        "  Y = []\n",
        "  Y.append(x_kit[i])\n",
        "  Y.append(y_kit[i])\n",
        "  dat_kit.append(Y)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H2jyDiaR5c_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_books = dat_books[:1700]\n",
        "test_books = dat_books[1700:]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaq_b1UibA0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dvd = dat_dvd[:1700]\n",
        "test_dvd = dat_dvd[1700:]\n",
        "\n",
        "train_ele = dat_ele[:1700]\n",
        "test_ele = dat_ele[1700:]\n",
        "\n",
        "train_kit = dat_kit[:1700]\n",
        "test_kit = dat_kit[1700:]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boqcy2Nrkh5u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7b65986e-c110-4833-8ff9-bcc2f1bb6dcb"
      },
      "source": [
        "# Doing the actual pre-processing of the dataset\n",
        "train_b, train_b_lengths = preprocess_dataset(train_books)\n",
        "test_b, test_b_lengths = preprocess_dataset(test_books)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done! Tokenizing Time=2.15s, #Sentences=1700\n",
            "Done! Tokenizing Time=0.54s, #Sentences=300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay11pzu5R66y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "24f1f3d6-10ab-49e0-8a8d-ff95b28710d5"
      },
      "source": [
        "train_e, train_e_lengths = preprocess_dataset(train_ele)\n",
        "test_e, test_e_lengths = preprocess_dataset(test_ele)\n",
        "\n",
        "train_d, train_d_lengths = preprocess_dataset(train_dvd)\n",
        "test_d, test_d_lengths = preprocess_dataset(test_dvd)\n",
        "\n",
        "train_k, train_k_lengths = preprocess_dataset(train_kit)\n",
        "test_k, test_k_lengths = preprocess_dataset(test_kit)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done! Tokenizing Time=1.24s, #Sentences=1700\n",
            "Done! Tokenizing Time=0.34s, #Sentences=300\n",
            "Done! Tokenizing Time=2.24s, #Sentences=1700\n",
            "Done! Tokenizing Time=0.54s, #Sentences=300\n",
            "Done! Tokenizing Time=1.04s, #Sentences=1700\n",
            "Done! Tokenizing Time=0.34s, #Sentences=300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnD1dlMddTIy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b4726bb3-1565-4ff3-a742-b329d8127288"
      },
      "source": [
        "# Construct the DataLoader for books\n",
        "\n",
        "def get_dataloader():\n",
        "\n",
        "    # Pad data, stack label and lengths\n",
        "    batchify_fn = nlp.data.batchify.Tuple(\n",
        "        nlp.data.batchify.Pad(axis=0, pad_val=0, ret_length=True),\n",
        "        nlp.data.batchify.Stack(dtype='float32'))\n",
        "    batch_sampler = nlp.data.sampler.FixedBucketSampler(\n",
        "        train_b_lengths,\n",
        "        batch_size=batch_size,\n",
        "        num_buckets=bucket_num,\n",
        "        ratio=bucket_ratio,\n",
        "        shuffle=True)\n",
        "    print(batch_sampler.stats())\n",
        "\n",
        "    # Construct a DataLoader object for both the training and test data\n",
        "    train_dataloader = gluon.data.DataLoader(\n",
        "        dataset=train_b,\n",
        "        batch_sampler=batch_sampler,\n",
        "        batchify_fn=batchify_fn)\n",
        "    test_dataloader = gluon.data.DataLoader(\n",
        "        dataset=test_b,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        batchify_fn=batchify_fn)\n",
        "    return train_dataloader, test_dataloader\n",
        "\n",
        "\n",
        "train_b_dataloader, test_b_dataloader = get_dataloader()\n",
        " \n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FixedBucketSampler:\n",
            "  sample_num=1700, batch_num=57\n",
            "  key=[12, 24, 36, 48, 60, 72, 84, 96, 108, 120]\n",
            "  cnt=[8, 42, 95, 75, 80, 95, 89, 87, 95, 1034]\n",
            "  batch_size=[64, 32, 32, 32, 32, 32, 32, 32, 32, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlaKCdK3RsDv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ea583cf9-7f09-4ff9-da2e-de6967d20159"
      },
      "source": [
        "# Construct the DataLoader for dvd\n",
        "\n",
        "def get_dataloader():\n",
        "\n",
        "    # Pad data, stack label and lengths\n",
        "    batchify_fn = nlp.data.batchify.Tuple(\n",
        "        nlp.data.batchify.Pad(axis=0, pad_val=0, ret_length=True),\n",
        "        nlp.data.batchify.Stack(dtype='float32'))\n",
        "    batch_sampler = nlp.data.sampler.FixedBucketSampler(\n",
        "        train_d_lengths,\n",
        "        batch_size=batch_size,\n",
        "        num_buckets=bucket_num,\n",
        "        ratio=bucket_ratio,\n",
        "        shuffle=True)\n",
        "    print(batch_sampler.stats())\n",
        "\n",
        "    # Construct a DataLoader object for both the training and test data\n",
        "    train_dataloader = gluon.data.DataLoader(\n",
        "        dataset=train_d,\n",
        "        batch_sampler=batch_sampler,\n",
        "        batchify_fn=batchify_fn)\n",
        "    test_dataloader = gluon.data.DataLoader(\n",
        "        dataset=test_d,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        batchify_fn=batchify_fn)\n",
        "    return train_dataloader, test_dataloader\n",
        "\n",
        "\n",
        "train_d_dataloader, test_d_dataloader = get_dataloader()\n",
        " \n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FixedBucketSampler:\n",
            "  sample_num=1700, batch_num=58\n",
            "  key=[21, 32, 43, 54, 65, 76, 87, 98, 109, 120]\n",
            "  cnt=[58, 72, 71, 95, 102, 91, 93, 82, 72, 964]\n",
            "  batch_size=[36, 32, 32, 32, 32, 32, 32, 32, 32, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwVtRDJNXMjj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f6419a63-1f5d-43c9-f0b6-4ed664910e4e"
      },
      "source": [
        "# Construct the DataLoader for electronics\n",
        "\n",
        "def get_dataloader():\n",
        "\n",
        "    # Pad data, stack label and lengths\n",
        "    batchify_fn = nlp.data.batchify.Tuple(\n",
        "        nlp.data.batchify.Pad(axis=0, pad_val=0, ret_length=True),\n",
        "        nlp.data.batchify.Stack(dtype='float32'))\n",
        "    batch_sampler = nlp.data.sampler.FixedBucketSampler(\n",
        "        train_e_lengths,\n",
        "        batch_size=batch_size,\n",
        "        num_buckets=bucket_num,\n",
        "        ratio=bucket_ratio,\n",
        "        shuffle=True)\n",
        "    print(batch_sampler.stats())\n",
        "\n",
        "    # Construct a DataLoader object for both the training and test data\n",
        "    train_dataloader = gluon.data.DataLoader(\n",
        "        dataset=train_e,\n",
        "        batch_sampler=batch_sampler,\n",
        "        batchify_fn=batchify_fn)\n",
        "    test_dataloader = gluon.data.DataLoader(\n",
        "        dataset=test_e,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        batchify_fn=batchify_fn)\n",
        "    return train_dataloader, test_dataloader\n",
        "\n",
        "\n",
        "train_e_dataloader, test_e_dataloader = get_dataloader()\n",
        " "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FixedBucketSampler:\n",
            "  sample_num=1700, batch_num=58\n",
            "  key=[21, 32, 43, 54, 65, 76, 87, 98, 109, 120]\n",
            "  cnt=[98, 126, 120, 134, 138, 100, 101, 87, 88, 708]\n",
            "  batch_size=[36, 32, 32, 32, 32, 32, 32, 32, 32, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgEENudPXSPR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1150b693-ffa3-42bc-d89c-01b801f7e490"
      },
      "source": [
        "\n",
        "# Construct the DataLoader for kitchen appliance\n",
        "\n",
        "def get_dataloader():\n",
        "\n",
        "    # Pad data, stack label and lengths\n",
        "    batchify_fn = nlp.data.batchify.Tuple(\n",
        "        nlp.data.batchify.Pad(axis=0, pad_val=0, ret_length=True),\n",
        "        nlp.data.batchify.Stack(dtype='float32'))\n",
        "    batch_sampler = nlp.data.sampler.FixedBucketSampler(\n",
        "        train_k_lengths,\n",
        "        batch_size=batch_size,\n",
        "        num_buckets=bucket_num,\n",
        "        ratio=bucket_ratio,\n",
        "        shuffle=True)\n",
        "    print(batch_sampler.stats())\n",
        "\n",
        "    # Construct a DataLoader object for both the training and test data\n",
        "    train_dataloader = gluon.data.DataLoader(\n",
        "        dataset=train_k,\n",
        "        batch_sampler=batch_sampler,\n",
        "        batchify_fn=batchify_fn)\n",
        "    test_dataloader = gluon.data.DataLoader(\n",
        "        dataset=test_k,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        batchify_fn=batchify_fn)\n",
        "    return train_dataloader, test_dataloader\n",
        "\n",
        "\n",
        "train_k_dataloader, test_k_dataloader = get_dataloader()\n",
        " "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FixedBucketSampler:\n",
            "  sample_num=1700, batch_num=58\n",
            "  key=[21, 32, 43, 54, 65, 76, 87, 98, 109, 120]\n",
            "  cnt=[100, 129, 141, 152, 128, 142, 134, 109, 84, 581]\n",
            "  batch_size=[36, 32, 32, 32, 32, 32, 32, 32, 32, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2Zj5NGxdYLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(net, dataloader, context):\n",
        "    loss = gluon.loss.SigmoidBCELoss()\n",
        "    total_L = 0.0\n",
        "    total_sample_num = 0\n",
        "    total_correct_num = 0\n",
        "    start_log_interval_time = time.time()\n",
        "\n",
        "    print('Begin Testing...')\n",
        "    for i, ((data, valid_length), label) in enumerate(dataloader):\n",
        "        data = mx.nd.transpose(data.as_in_context(context))\n",
        "        valid_length = valid_length.as_in_context(context).astype(np.float32)\n",
        "        label = label.as_in_context(context)\n",
        "        output = net(data, valid_length)\n",
        "\n",
        "        L = loss(output, label)\n",
        "        pred = (output > 0.5).reshape(-1)\n",
        "        total_L += L.sum().asscalar()\n",
        "        total_sample_num += label.shape[0]\n",
        "        total_correct_num += (pred == label).sum().asscalar()\n",
        "\n",
        "        if (i + 1) % log_interval == 0:\n",
        "            print('[Batch {}/{}] elapsed {:.2f} s'.format(\n",
        "                i + 1, len(dataloader),\n",
        "                time.time() - start_log_interval_time))\n",
        "            start_log_interval_time = time.time()\n",
        "\n",
        "    avg_L = total_L / float(total_sample_num)\n",
        "    acc = total_correct_num / float(total_sample_num)\n",
        "\n",
        "    return avg_L, acc"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hppm_gADdm_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "049f9f3d-df6c-48e1-a0bd-581d9c9e3a56"
      },
      "source": [
        "#pre-trained model performance in books domain\n",
        "def train(net, context, epochs):\n",
        "    trainer = gluon.Trainer(net.collect_params(), 'ftml',\n",
        "                            {'learning_rate': learning_rate})\n",
        "    loss = gluon.loss.SigmoidBCELoss()\n",
        "\n",
        "    parameters = net.collect_params().values()\n",
        "\n",
        "    # Training/Testing\n",
        "    for epoch in range(epochs):\n",
        "        # Epoch training stats\n",
        "        start_epoch_time = time.time()\n",
        "        epoch_L = 0.0\n",
        "        epoch_sent_num = 0\n",
        "        epoch_wc = 0\n",
        "        # Log interval training stats\n",
        "        start_log_interval_time = time.time()\n",
        "        log_interval_wc = 0\n",
        "        log_interval_sent_num = 0\n",
        "        log_interval_L = 0.0\n",
        "\n",
        "        for i, ((data, length), label) in enumerate(train_b_dataloader):\n",
        "            L = 0\n",
        "            wc = length.sum().asscalar()\n",
        "            log_interval_wc += wc\n",
        "            epoch_wc += wc\n",
        "            log_interval_sent_num += data.shape[1]\n",
        "            epoch_sent_num += data.shape[1]\n",
        "            with autograd.record():\n",
        "                output = net(data.as_in_context(context).T,\n",
        "                             length.as_in_context(context)\n",
        "                                   .astype(np.float32))\n",
        "                L = L + loss(output, label.as_in_context(context)).mean()\n",
        "            L.backward()\n",
        "            # Clip gradient\n",
        "            if grad_clip:\n",
        "                gluon.utils.clip_global_norm(\n",
        "                    [p.grad(context) for p in parameters],\n",
        "                    grad_clip)\n",
        "            # Update parameter\n",
        "            trainer.step(1)\n",
        "            log_interval_L += L.asscalar()\n",
        "            epoch_L += L.asscalar()\n",
        "            if (i + 1) % log_interval == 0:\n",
        "                print(\n",
        "                    '[Epoch {} Batch {}/{}] elapsed {:.2f} s, '\n",
        "                    'avg loss {:.6f}, throughput {:.2f}K wps'.format(\n",
        "                        epoch, i + 1, len(train_b_dataloader),\n",
        "                        time.time() - start_log_interval_time,\n",
        "                        log_interval_L / log_interval_sent_num, log_interval_wc\n",
        "                        / 1000 / (time.time() - start_log_interval_time)))\n",
        "                # Clear log interval training stats\n",
        "                start_log_interval_time = time.time()\n",
        "                log_interval_wc = 0\n",
        "                log_interval_sent_num = 0\n",
        "                log_interval_L = 0\n",
        "        end_epoch_time = time.time()\n",
        "        train_avg_L, train_acc = evaluate(net,train_b_dataloader,context)\n",
        "        test_avg_L, test_acc = evaluate(net, test_b_dataloader, context)\n",
        "        print('[Epoch {}] train avg loss {:.6f}, train acc{:.4f} test acc {:.4f}'\n",
        "              'test avg loss {:.6f}, throughput {:.2f}K wps'.format(\n",
        "                  epoch, epoch_L / epoch_sent_num, train_acc, test_acc, test_avg_L,\n",
        "                  epoch_wc / 1000 / (end_epoch_time - start_epoch_time)))\n",
        "        \n",
        "\n",
        "history1 = train(net, context, epochs)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 0] train avg loss 0.006833, train acc0.5888 test acc 0.0000test avg loss 0.873851, throughput 3.02K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 1] train avg loss 0.005370, train acc0.9341 test acc 0.5433test avg loss 0.682347, throughput 3.01K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 2] train avg loss 0.002082, train acc0.9935 test acc 0.6333test avg loss 0.918566, throughput 2.88K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 3] train avg loss 0.000636, train acc0.9994 test acc 0.6667test avg loss 1.224674, throughput 2.82K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 4] train avg loss 0.000186, train acc1.0000 test acc 0.6467test avg loss 1.980648, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 5] train avg loss 0.000083, train acc1.0000 test acc 0.6367test avg loss 2.333720, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 6] train avg loss 0.000117, train acc1.0000 test acc 0.6233test avg loss 1.830645, throughput 2.70K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 7] train avg loss 0.000319, train acc1.0000 test acc 0.6533test avg loss 1.666439, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 8] train avg loss 0.000061, train acc1.0000 test acc 0.6633test avg loss 1.918140, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 9] train avg loss 0.000034, train acc1.0000 test acc 0.6500test avg loss 2.230419, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 10] train avg loss 0.000026, train acc1.0000 test acc 0.6500test avg loss 2.444925, throughput 2.70K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 11] train avg loss 0.000021, train acc1.0000 test acc 0.6467test avg loss 2.572471, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 12] train avg loss 0.000016, train acc1.0000 test acc 0.6533test avg loss 2.669656, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 13] train avg loss 0.000013, train acc1.0000 test acc 0.6600test avg loss 2.753868, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 14] train avg loss 0.000012, train acc1.0000 test acc 0.6600test avg loss 2.841281, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 15] train avg loss 0.000011, train acc1.0000 test acc 0.6633test avg loss 2.903277, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 16] train avg loss 0.000009, train acc1.0000 test acc 0.6600test avg loss 2.960558, throughput 2.70K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 17] train avg loss 0.000008, train acc1.0000 test acc 0.6567test avg loss 3.033566, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 18] train avg loss 0.000007, train acc1.0000 test acc 0.6533test avg loss 3.109417, throughput 2.70K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 19] train avg loss 0.000006, train acc1.0000 test acc 0.6500test avg loss 3.169685, throughput 2.73K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 20] train avg loss 0.000006, train acc1.0000 test acc 0.6567test avg loss 3.226356, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 21] train avg loss 0.000005, train acc1.0000 test acc 0.6533test avg loss 3.283880, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 22] train avg loss 0.000005, train acc1.0000 test acc 0.6567test avg loss 3.342471, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 23] train avg loss 0.000004, train acc1.0000 test acc 0.6433test avg loss 3.470171, throughput 2.70K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 24] train avg loss 0.000004, train acc1.0000 test acc 0.6467test avg loss 3.490807, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 25] train avg loss 0.000003, train acc1.0000 test acc 0.6467test avg loss 3.523708, throughput 2.70K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 26] train avg loss 0.000003, train acc1.0000 test acc 0.6467test avg loss 3.558095, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 27] train avg loss 0.000003, train acc1.0000 test acc 0.6467test avg loss 3.602209, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 28] train avg loss 0.000003, train acc1.0000 test acc 0.6467test avg loss 3.640049, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 29] train avg loss 0.000002, train acc1.0000 test acc 0.6467test avg loss 3.680028, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 30] train avg loss 0.000002, train acc1.0000 test acc 0.6467test avg loss 3.713618, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 31] train avg loss 0.000002, train acc1.0000 test acc 0.6467test avg loss 3.753909, throughput 2.70K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 32] train avg loss 0.000002, train acc1.0000 test acc 0.6467test avg loss 3.811769, throughput 2.70K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 33] train avg loss 0.000002, train acc1.0000 test acc 0.6467test avg loss 3.840396, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 34] train avg loss 0.000002, train acc1.0000 test acc 0.6433test avg loss 3.879470, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 35] train avg loss 0.000002, train acc1.0000 test acc 0.6433test avg loss 3.917956, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 36] train avg loss 0.000001, train acc1.0000 test acc 0.6433test avg loss 3.930823, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 37] train avg loss 0.000001, train acc1.0000 test acc 0.6467test avg loss 3.964306, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 38] train avg loss 0.000001, train acc1.0000 test acc 0.6467test avg loss 3.995331, throughput 2.62K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 39] train avg loss 0.000001, train acc1.0000 test acc 0.6467test avg loss 4.024892, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 40] train avg loss 0.000001, train acc1.0000 test acc 0.6467test avg loss 4.063608, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 41] train avg loss 0.000001, train acc1.0000 test acc 0.6467test avg loss 4.093139, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 42] train avg loss 0.000001, train acc1.0000 test acc 0.6500test avg loss 4.115296, throughput 2.70K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 43] train avg loss 0.000001, train acc1.0000 test acc 0.6500test avg loss 4.135347, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 44] train avg loss 0.000001, train acc1.0000 test acc 0.6500test avg loss 4.159487, throughput 2.70K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 45] train avg loss 0.000001, train acc1.0000 test acc 0.6500test avg loss 4.184985, throughput 2.59K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 46] train avg loss 0.000001, train acc1.0000 test acc 0.6500test avg loss 4.215315, throughput 2.69K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 47] train avg loss 0.000001, train acc1.0000 test acc 0.6433test avg loss 4.255597, throughput 2.70K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 48] train avg loss 0.000001, train acc1.0000 test acc 0.6433test avg loss 4.296557, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 49] train avg loss 0.000001, train acc1.0000 test acc 0.6400test avg loss 4.328264, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 50] train avg loss 0.000001, train acc1.0000 test acc 0.6400test avg loss 4.351221, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 51] train avg loss 0.000001, train acc1.0000 test acc 0.6400test avg loss 4.389844, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 52] train avg loss 0.000001, train acc1.0000 test acc 0.6367test avg loss 4.431166, throughput 2.62K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 53] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 4.457456, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 54] train avg loss 0.000000, train acc1.0000 test acc 0.6400test avg loss 4.486487, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 55] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 4.519670, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 56] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 4.550446, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 57] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 4.588846, throughput 2.70K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 58] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 4.615209, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 59] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 4.639839, throughput 2.60K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 60] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 4.663287, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 61] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 4.685558, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 62] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 4.719883, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 63] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 4.745607, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 64] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 4.782839, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 65] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 4.812054, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 66] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 4.834840, throughput 2.60K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 67] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 4.860909, throughput 2.69K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 68] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 4.881754, throughput 2.70K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 69] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 4.910191, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 70] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 4.935602, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 71] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 4.959666, throughput 2.70K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 72] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 4.977364, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 73] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 5.002171, throughput 2.61K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 74] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 5.022599, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 75] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 5.040920, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 76] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 5.057572, throughput 2.70K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 77] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 5.080343, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 78] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 5.098087, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 79] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 5.118166, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 80] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 5.132507, throughput 2.62K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 81] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 5.149841, throughput 2.70K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 82] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 5.163381, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 83] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 5.181190, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 84] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 5.201353, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 85] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 5.210420, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 86] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 5.224947, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 87] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 5.249394, throughput 2.62K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 88] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 5.266948, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 89] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 5.283149, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 90] train avg loss 0.000000, train acc1.0000 test acc 0.6333test avg loss 5.296072, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 91] train avg loss 0.000000, train acc1.0000 test acc 0.6333test avg loss 5.310343, throughput 2.71K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 92] train avg loss 0.000000, train acc1.0000 test acc 0.6333test avg loss 5.331786, throughput 2.70K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 93] train avg loss 0.000000, train acc1.0000 test acc 0.6367test avg loss 5.324965, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 94] train avg loss 0.000000, train acc1.0000 test acc 0.6400test avg loss 5.337713, throughput 2.61K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 95] train avg loss 0.000000, train acc1.0000 test acc 0.6400test avg loss 5.356246, throughput 2.70K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 96] train avg loss 0.000000, train acc1.0000 test acc 0.6400test avg loss 5.377635, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 97] train avg loss 0.000000, train acc1.0000 test acc 0.6400test avg loss 5.398527, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 98] train avg loss 0.000000, train acc1.0000 test acc 0.6400test avg loss 5.412212, throughput 2.72K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 99] train avg loss 0.000000, train acc1.0000 test acc 0.6400test avg loss 5.426717, throughput 2.70K wps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kEFmZijdqzp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a35fe713-88a5-424f-c22c-4ef84579f2bf"
      },
      "source": [
        "# pre-trained model performance in dvd domain\n",
        "def train(net, context, epochs):\n",
        "    trainer = gluon.Trainer(net.collect_params(), 'ftml',\n",
        "                            {'learning_rate': learning_rate})\n",
        "    loss = gluon.loss.SigmoidBCELoss()\n",
        "\n",
        "    parameters = net.collect_params().values()\n",
        "\n",
        "    # Training/Testing\n",
        "    for epoch in range(epochs):\n",
        "        # Epoch training stats\n",
        "        start_epoch_time = time.time()\n",
        "        epoch_L = 0.0\n",
        "        epoch_sent_num = 0\n",
        "        epoch_wc = 0\n",
        "        # Log interval training stats\n",
        "        start_log_interval_time = time.time()\n",
        "        log_interval_wc = 0\n",
        "        log_interval_sent_num = 0\n",
        "        log_interval_L = 0.0\n",
        "\n",
        "        for i, ((data, length), label) in enumerate(train_d_dataloader):\n",
        "            L = 0\n",
        "            wc = length.sum().asscalar()\n",
        "            log_interval_wc += wc\n",
        "            epoch_wc += wc\n",
        "            log_interval_sent_num += data.shape[1]\n",
        "            epoch_sent_num += data.shape[1]\n",
        "            with autograd.record():\n",
        "                output = net(data.as_in_context(context).T,\n",
        "                             length.as_in_context(context)\n",
        "                                   .astype(np.float32))\n",
        "                L = L + loss(output, label.as_in_context(context)).mean()\n",
        "            L.backward()\n",
        "            # Clip gradient\n",
        "            if grad_clip:\n",
        "                gluon.utils.clip_global_norm(\n",
        "                    [p.grad(context) for p in parameters],\n",
        "                    grad_clip)\n",
        "            # Update parameter\n",
        "            trainer.step(1)\n",
        "            log_interval_L += L.asscalar()\n",
        "            epoch_L += L.asscalar()\n",
        "            if (i + 1) % log_interval == 0:\n",
        "                print(\n",
        "                    '[Epoch {} Batch {}/{}] elapsed {:.2f} s, '\n",
        "                    'avg loss {:.6f}, throughput {:.2f}K wps'.format(\n",
        "                        epoch, i + 1, len(train_d_dataloader),\n",
        "                        time.time() - start_log_interval_time,\n",
        "                        log_interval_L / log_interval_sent_num, log_interval_wc\n",
        "                        / 1000 / (time.time() - start_log_interval_time)))\n",
        "                # Clear log interval training stats\n",
        "                start_log_interval_time = time.time()\n",
        "                log_interval_wc = 0\n",
        "                log_interval_sent_num = 0\n",
        "                log_interval_L = 0\n",
        "        end_epoch_time = time.time()\n",
        "        train_avg_L, train_acc = evaluate(net, train_d_dataloader, context)\n",
        "        test_avg_L, test_acc = evaluate(net, test_d_dataloader, context)\n",
        "        print('[Epoch {}] train avg loss {:.6f}, train acc{:.4f}, test acc {:.4f}, '\n",
        "              'test avg loss {:.6f}, throughput {:.2f}K wps'.format(\n",
        "                  epoch, epoch_L / epoch_sent_num, train_acc, test_acc, test_avg_L,\n",
        "                  epoch_wc / 1000 / (end_epoch_time - start_epoch_time)))\n",
        "        \n",
        "\n",
        "history2 = train(net, context, epochs)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 0] train avg loss 0.000179, train acc0.9965, test acc 0.4533, test avg loss 3.978074, throughput 2.92K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 1] train avg loss 0.000057, train acc0.9994, test acc 0.5633, test avg loss 2.792423, throughput 2.94K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 2] train avg loss 0.000014, train acc1.0000, test acc 0.6267, test avg loss 1.921606, throughput 2.93K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 3] train avg loss 0.000005, train acc1.0000, test acc 0.5800, test avg loss 2.286801, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 4] train avg loss 0.000001, train acc1.0000, test acc 0.5800, test avg loss 2.324768, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 5] train avg loss 0.000001, train acc1.0000, test acc 0.5767, test avg loss 2.356763, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 6] train avg loss 0.000001, train acc1.0000, test acc 0.5767, test avg loss 2.387554, throughput 2.66K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 7] train avg loss 0.000001, train acc1.0000, test acc 0.5733, test avg loss 2.414695, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 8] train avg loss 0.000001, train acc1.0000, test acc 0.5767, test avg loss 2.432773, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 9] train avg loss 0.000001, train acc1.0000, test acc 0.5767, test avg loss 2.465823, throughput 2.66K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 10] train avg loss 0.000001, train acc1.0000, test acc 0.5767, test avg loss 2.485055, throughput 2.56K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 11] train avg loss 0.000001, train acc1.0000, test acc 0.5767, test avg loss 2.505523, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 12] train avg loss 0.000001, train acc1.0000, test acc 0.5733, test avg loss 2.525189, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 13] train avg loss 0.000001, train acc1.0000, test acc 0.5767, test avg loss 2.546843, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 14] train avg loss 0.000001, train acc1.0000, test acc 0.5800, test avg loss 2.568094, throughput 2.66K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 15] train avg loss 0.000000, train acc1.0000, test acc 0.5800, test avg loss 2.580398, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 16] train avg loss 0.000000, train acc1.0000, test acc 0.5800, test avg loss 2.600315, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 17] train avg loss 0.000000, train acc1.0000, test acc 0.5800, test avg loss 2.615921, throughput 2.55K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 18] train avg loss 0.000000, train acc1.0000, test acc 0.5800, test avg loss 2.637876, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 19] train avg loss 0.000000, train acc1.0000, test acc 0.5767, test avg loss 2.657343, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 20] train avg loss 0.000000, train acc1.0000, test acc 0.5767, test avg loss 2.672344, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 21] train avg loss 0.000000, train acc1.0000, test acc 0.5767, test avg loss 2.689294, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 22] train avg loss 0.000000, train acc1.0000, test acc 0.5767, test avg loss 2.710257, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 23] train avg loss 0.000000, train acc1.0000, test acc 0.5800, test avg loss 2.729650, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 24] train avg loss 0.000000, train acc1.0000, test acc 0.5800, test avg loss 2.750937, throughput 2.56K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 25] train avg loss 0.000000, train acc1.0000, test acc 0.5800, test avg loss 2.770041, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 26] train avg loss 0.000000, train acc1.0000, test acc 0.5767, test avg loss 2.786941, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 27] train avg loss 0.000000, train acc1.0000, test acc 0.5767, test avg loss 2.807406, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 28] train avg loss 0.000000, train acc1.0000, test acc 0.5733, test avg loss 2.828477, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 29] train avg loss 0.000000, train acc1.0000, test acc 0.5733, test avg loss 2.848220, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 30] train avg loss 0.000000, train acc1.0000, test acc 0.5700, test avg loss 2.869977, throughput 2.66K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 31] train avg loss 0.000000, train acc1.0000, test acc 0.5667, test avg loss 2.884011, throughput 2.66K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 32] train avg loss 0.000000, train acc1.0000, test acc 0.5633, test avg loss 2.901585, throughput 2.66K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 33] train avg loss 0.000000, train acc1.0000, test acc 0.5633, test avg loss 2.919696, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 34] train avg loss 0.000000, train acc1.0000, test acc 0.5633, test avg loss 2.940273, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 35] train avg loss 0.000000, train acc1.0000, test acc 0.5633, test avg loss 2.961584, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 36] train avg loss 0.000000, train acc1.0000, test acc 0.5633, test avg loss 2.982446, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 37] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.003435, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 38] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.014290, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 39] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.025768, throughput 2.66K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 40] train avg loss 0.000000, train acc1.0000, test acc 0.5600, test avg loss 3.031994, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 41] train avg loss 0.000000, train acc1.0000, test acc 0.5600, test avg loss 3.044340, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 42] train avg loss 0.000000, train acc1.0000, test acc 0.5600, test avg loss 3.055783, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 43] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.074213, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 44] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.088445, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 45] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.103179, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 46] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.114313, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 47] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.124463, throughput 2.66K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 48] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.133444, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 49] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.136358, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 50] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.148834, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 51] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.153710, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 52] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.166121, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 53] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.180486, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 54] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.192492, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 55] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.206487, throughput 2.66K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 56] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.221008, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 57] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.228099, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 58] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.237113, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 59] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.246438, throughput 2.66K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 60] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.254663, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 61] train avg loss 0.000000, train acc1.0000, test acc 0.5600, test avg loss 3.264384, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 62] train avg loss 0.000000, train acc1.0000, test acc 0.5600, test avg loss 3.274243, throughput 2.66K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 63] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.283402, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 64] train avg loss 0.000000, train acc1.0000, test acc 0.5600, test avg loss 3.292736, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 65] train avg loss 0.000000, train acc1.0000, test acc 0.5600, test avg loss 3.305391, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 66] train avg loss 0.000000, train acc1.0000, test acc 0.5600, test avg loss 3.313897, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 67] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.326271, throughput 2.56K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 68] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.336357, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 69] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.349288, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 70] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.357349, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 71] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.364690, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 72] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.375928, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 73] train avg loss 0.000000, train acc1.0000, test acc 0.5567, test avg loss 3.383902, throughput 2.63K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 74] train avg loss 0.000000, train acc1.0000, test acc 0.5600, test avg loss 3.394278, throughput 2.53K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 75] train avg loss 0.000000, train acc1.0000, test acc 0.5600, test avg loss 3.395126, throughput 2.63K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 76] train avg loss 0.000000, train acc1.0000, test acc 0.5600, test avg loss 3.406341, throughput 2.63K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 77] train avg loss 0.000000, train acc1.0000, test acc 0.5600, test avg loss 3.416791, throughput 2.63K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 78] train avg loss 0.000000, train acc1.0000, test acc 0.5600, test avg loss 3.429312, throughput 2.63K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 79] train avg loss 0.000000, train acc1.0000, test acc 0.5600, test avg loss 3.440154, throughput 2.63K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 80] train avg loss 0.000000, train acc1.0000, test acc 0.5600, test avg loss 3.450970, throughput 2.65K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 81] train avg loss 0.000000, train acc1.0000, test acc 0.5600, test avg loss 3.458763, throughput 2.53K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 82] train avg loss 0.000000, train acc1.0000, test acc 0.5600, test avg loss 3.473117, throughput 2.63K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 83] train avg loss 0.000000, train acc1.0000, test acc 0.5600, test avg loss 3.490324, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 84] train avg loss 0.000000, train acc1.0000, test acc 0.5533, test avg loss 3.504217, throughput 2.62K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 85] train avg loss 0.000000, train acc1.0000, test acc 0.5533, test avg loss 3.512932, throughput 2.63K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 86] train avg loss 0.000000, train acc1.0000, test acc 0.5533, test avg loss 3.519209, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 87] train avg loss 0.000000, train acc1.0000, test acc 0.5533, test avg loss 3.531501, throughput 2.62K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 88] train avg loss 0.000000, train acc1.0000, test acc 0.5533, test avg loss 3.544613, throughput 2.53K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 89] train avg loss 0.000000, train acc1.0000, test acc 0.5533, test avg loss 3.557076, throughput 2.62K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 90] train avg loss 0.000000, train acc1.0000, test acc 0.5533, test avg loss 3.567262, throughput 2.62K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 91] train avg loss 0.000000, train acc1.0000, test acc 0.5533, test avg loss 3.576805, throughput 2.62K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 92] train avg loss 0.000000, train acc1.0000, test acc 0.5533, test avg loss 3.589394, throughput 2.62K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 93] train avg loss 0.000000, train acc1.0000, test acc 0.5500, test avg loss 3.599835, throughput 2.63K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 94] train avg loss 0.000000, train acc1.0000, test acc 0.5500, test avg loss 3.610120, throughput 2.63K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 95] train avg loss 0.000000, train acc1.0000, test acc 0.5500, test avg loss 3.620972, throughput 2.53K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 96] train avg loss 0.000000, train acc1.0000, test acc 0.5500, test avg loss 3.635263, throughput 2.63K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 97] train avg loss 0.000000, train acc1.0000, test acc 0.5500, test avg loss 3.646268, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 98] train avg loss 0.000000, train acc1.0000, test acc 0.5500, test avg loss 3.657687, throughput 2.64K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 99] train avg loss 0.000000, train acc1.0000, test acc 0.5500, test avg loss 3.669705, throughput 2.64K wps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwoBGsc3d_1L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be7e004e-0cf4-4437-e7e9-f9f8ab9c9383"
      },
      "source": [
        "#pre-trained model performance in electronics domain\n",
        "def train(net, context, epochs):\n",
        "    trainer = gluon.Trainer(net.collect_params(), 'ftml',\n",
        "                            {'learning_rate': learning_rate})\n",
        "    loss = gluon.loss.SigmoidBCELoss()\n",
        "\n",
        "    parameters = net.collect_params().values()\n",
        "\n",
        "    # Training/Testing\n",
        "    for epoch in range(epochs):\n",
        "        # Epoch training stats\n",
        "        start_epoch_time = time.time()\n",
        "        epoch_L = 0.0\n",
        "        epoch_sent_num = 0\n",
        "        epoch_wc = 0\n",
        "        # Log interval training stats\n",
        "        start_log_interval_time = time.time()\n",
        "        log_interval_wc = 0\n",
        "        log_interval_sent_num = 0\n",
        "        log_interval_L = 0.0\n",
        "\n",
        "        for i, ((data, length), label) in enumerate(train_e_dataloader):\n",
        "            L = 0\n",
        "            wc = length.sum().asscalar()\n",
        "            log_interval_wc += wc\n",
        "            epoch_wc += wc\n",
        "            log_interval_sent_num += data.shape[1]\n",
        "            epoch_sent_num += data.shape[1]\n",
        "            with autograd.record():\n",
        "                output = net(data.as_in_context(context).T,\n",
        "                             length.as_in_context(context)\n",
        "                                   .astype(np.float32))\n",
        "                L = L + loss(output, label.as_in_context(context)).mean()\n",
        "            L.backward()\n",
        "            # Clip gradient\n",
        "            if grad_clip:\n",
        "                gluon.utils.clip_global_norm(\n",
        "                    [p.grad(context) for p in parameters],\n",
        "                    grad_clip)\n",
        "            # Update parameter\n",
        "            trainer.step(1)\n",
        "            log_interval_L += L.asscalar()\n",
        "            epoch_L += L.asscalar()\n",
        "            if (i + 1) % log_interval == 0:\n",
        "                print(\n",
        "                    '[Epoch {} Batch {}/{}] elapsed {:.2f} s, '\n",
        "                    'avg loss {:.6f}, throughput {:.2f}K wps'.format(\n",
        "                        epoch, i + 1, len(train_e_dataloader),\n",
        "                        time.time() - start_log_interval_time,\n",
        "                        log_interval_L / log_interval_sent_num, log_interval_wc\n",
        "                        / 1000 / (time.time() - start_log_interval_time)))\n",
        "                # Clear log interval training stats\n",
        "                start_log_interval_time = time.time()\n",
        "                log_interval_wc = 0\n",
        "                log_interval_sent_num = 0\n",
        "                log_interval_L = 0\n",
        "        end_epoch_time = time.time()\n",
        "        train_avg_L, train_acc = evaluate(net, train_e_dataloader, context)\n",
        "        test_avg_L, test_acc = evaluate(net, test_e_dataloader, context)\n",
        "        print('[Epoch {}] train avg loss {:.6f}, train acc{:.4f}, test acc {:.4f}, '\n",
        "              'test avg loss {:.6f}, throughput {:.2f}K wps'.format(\n",
        "                  epoch, epoch_L / epoch_sent_num, train_acc, test_acc, test_avg_L,\n",
        "                  epoch_wc / 1000 / (end_epoch_time - start_epoch_time)))\n",
        "        \n",
        "\n",
        "history3 = train(net, context, epochs)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 0] train avg loss 0.000186, train acc0.9982, test acc 0.5767, test avg loss 1.914706, throughput 2.76K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 1] train avg loss 0.000320, train acc0.9994, test acc 0.6400, test avg loss 1.312313, throughput 2.76K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 2] train avg loss 0.000054, train acc1.0000, test acc 0.5867, test avg loss 1.686159, throughput 2.77K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 3] train avg loss 0.000013, train acc1.0000, test acc 0.5867, test avg loss 1.802204, throughput 2.57K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 4] train avg loss 0.000009, train acc1.0000, test acc 0.5900, test avg loss 1.839378, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 5] train avg loss 0.000007, train acc1.0000, test acc 0.5900, test avg loss 1.897036, throughput 2.47K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 6] train avg loss 0.000006, train acc1.0000, test acc 0.5900, test avg loss 1.950351, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 7] train avg loss 0.000004, train acc1.0000, test acc 0.5867, test avg loss 1.971517, throughput 2.38K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 8] train avg loss 0.000004, train acc1.0000, test acc 0.5933, test avg loss 1.993429, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 9] train avg loss 0.000003, train acc1.0000, test acc 0.5933, test avg loss 2.011190, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 10] train avg loss 0.000003, train acc1.0000, test acc 0.5933, test avg loss 2.025756, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 11] train avg loss 0.000002, train acc1.0000, test acc 0.5967, test avg loss 2.054081, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 12] train avg loss 0.000002, train acc1.0000, test acc 0.5967, test avg loss 2.078261, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 13] train avg loss 0.000002, train acc1.0000, test acc 0.5967, test avg loss 2.074213, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 14] train avg loss 0.000536, train acc0.9841, test acc 0.4633, test avg loss 1.587488, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 15] train avg loss 0.000476, train acc0.9988, test acc 0.6400, test avg loss 1.070767, throughput 2.38K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 16] train avg loss 0.000052, train acc1.0000, test acc 0.6067, test avg loss 1.275764, throughput 2.47K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 17] train avg loss 0.000011, train acc1.0000, test acc 0.6067, test avg loss 1.387270, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 18] train avg loss 0.000008, train acc1.0000, test acc 0.6067, test avg loss 1.466158, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 19] train avg loss 0.000005, train acc1.0000, test acc 0.6033, test avg loss 1.516163, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 20] train avg loss 0.000005, train acc1.0000, test acc 0.6033, test avg loss 1.550875, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 21] train avg loss 0.000004, train acc1.0000, test acc 0.6000, test avg loss 1.592945, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 22] train avg loss 0.000003, train acc1.0000, test acc 0.6000, test avg loss 1.621742, throughput 2.41K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 23] train avg loss 0.000003, train acc1.0000, test acc 0.6000, test avg loss 1.664949, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 24] train avg loss 0.000002, train acc1.0000, test acc 0.6000, test avg loss 1.695814, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 25] train avg loss 0.000002, train acc1.0000, test acc 0.6000, test avg loss 1.730759, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 26] train avg loss 0.000002, train acc1.0000, test acc 0.6000, test avg loss 1.751506, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 27] train avg loss 0.000002, train acc1.0000, test acc 0.6000, test avg loss 1.774995, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 28] train avg loss 0.000002, train acc1.0000, test acc 0.5967, test avg loss 1.803171, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 29] train avg loss 0.000001, train acc1.0000, test acc 0.5967, test avg loss 1.824508, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 30] train avg loss 0.000001, train acc1.0000, test acc 0.5967, test avg loss 1.845209, throughput 2.39K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 31] train avg loss 0.000001, train acc1.0000, test acc 0.5967, test avg loss 1.865992, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 32] train avg loss 0.000001, train acc1.0000, test acc 0.5967, test avg loss 1.880898, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 33] train avg loss 0.000001, train acc1.0000, test acc 0.5967, test avg loss 1.894098, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 34] train avg loss 0.000001, train acc1.0000, test acc 0.5967, test avg loss 1.906541, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 35] train avg loss 0.000001, train acc1.0000, test acc 0.5967, test avg loss 1.919175, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 36] train avg loss 0.000001, train acc1.0000, test acc 0.5933, test avg loss 1.934468, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 37] train avg loss 0.000001, train acc1.0000, test acc 0.5900, test avg loss 1.950408, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 38] train avg loss 0.000001, train acc1.0000, test acc 0.5900, test avg loss 1.962838, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 39] train avg loss 0.000001, train acc1.0000, test acc 0.6000, test avg loss 1.974191, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 40] train avg loss 0.000001, train acc1.0000, test acc 0.6000, test avg loss 1.983527, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 41] train avg loss 0.000001, train acc1.0000, test acc 0.6067, test avg loss 1.996105, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 42] train avg loss 0.000001, train acc1.0000, test acc 0.6033, test avg loss 2.007883, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 43] train avg loss 0.000001, train acc1.0000, test acc 0.6033, test avg loss 2.021326, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 44] train avg loss 0.000001, train acc1.0000, test acc 0.6067, test avg loss 2.032323, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 45] train avg loss 0.000001, train acc1.0000, test acc 0.6067, test avg loss 2.044616, throughput 2.39K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 46] train avg loss 0.000000, train acc1.0000, test acc 0.6033, test avg loss 2.061992, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 47] train avg loss 0.000000, train acc1.0000, test acc 0.6000, test avg loss 2.072612, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 48] train avg loss 0.000000, train acc1.0000, test acc 0.6033, test avg loss 2.085165, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 49] train avg loss 0.000000, train acc1.0000, test acc 0.6033, test avg loss 2.098125, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 50] train avg loss 0.000000, train acc1.0000, test acc 0.6033, test avg loss 2.110521, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 51] train avg loss 0.000000, train acc1.0000, test acc 0.6067, test avg loss 2.123821, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 52] train avg loss 0.000000, train acc1.0000, test acc 0.6067, test avg loss 2.137069, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 53] train avg loss 0.000000, train acc1.0000, test acc 0.6000, test avg loss 2.152225, throughput 2.39K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 54] train avg loss 0.000000, train acc1.0000, test acc 0.6033, test avg loss 2.163110, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 55] train avg loss 0.000000, train acc1.0000, test acc 0.6033, test avg loss 2.176378, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 56] train avg loss 0.000000, train acc1.0000, test acc 0.6000, test avg loss 2.189854, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 57] train avg loss 0.000000, train acc1.0000, test acc 0.6000, test avg loss 2.202561, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 58] train avg loss 0.000000, train acc1.0000, test acc 0.5967, test avg loss 2.216078, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 59] train avg loss 0.000000, train acc1.0000, test acc 0.5933, test avg loss 2.226646, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 60] train avg loss 0.000000, train acc1.0000, test acc 0.5933, test avg loss 2.240624, throughput 2.42K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 61] train avg loss 0.000000, train acc1.0000, test acc 0.5933, test avg loss 2.251607, throughput 2.50K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 62] train avg loss 0.000000, train acc1.0000, test acc 0.5933, test avg loss 2.264001, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 63] train avg loss 0.000000, train acc1.0000, test acc 0.5967, test avg loss 2.276456, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 64] train avg loss 0.000000, train acc1.0000, test acc 0.6000, test avg loss 2.289923, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 65] train avg loss 0.000000, train acc1.0000, test acc 0.5967, test avg loss 2.304124, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 66] train avg loss 0.000000, train acc1.0000, test acc 0.5967, test avg loss 2.315614, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 67] train avg loss 0.000000, train acc1.0000, test acc 0.5967, test avg loss 2.327467, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 68] train avg loss 0.000000, train acc1.0000, test acc 0.5867, test avg loss 2.369553, throughput 2.38K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 69] train avg loss 0.000000, train acc1.0000, test acc 0.6100, test avg loss 2.317909, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 70] train avg loss 0.000000, train acc1.0000, test acc 0.6133, test avg loss 2.322462, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 71] train avg loss 0.000000, train acc1.0000, test acc 0.6067, test avg loss 2.336833, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 72] train avg loss 0.000000, train acc1.0000, test acc 0.6067, test avg loss 2.349782, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 73] train avg loss 0.000000, train acc1.0000, test acc 0.6067, test avg loss 2.360761, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 74] train avg loss 0.000000, train acc1.0000, test acc 0.6033, test avg loss 2.377136, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 75] train avg loss 0.000000, train acc1.0000, test acc 0.6033, test avg loss 2.389366, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 76] train avg loss 0.000000, train acc1.0000, test acc 0.6033, test avg loss 2.402550, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 77] train avg loss 0.000000, train acc1.0000, test acc 0.6033, test avg loss 2.416913, throughput 2.49K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 78] train avg loss 0.000000, train acc1.0000, test acc 0.6033, test avg loss 2.427335, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 79] train avg loss 0.000000, train acc1.0000, test acc 0.6033, test avg loss 2.435921, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 80] train avg loss 0.000000, train acc1.0000, test acc 0.6033, test avg loss 2.450293, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 81] train avg loss 0.000000, train acc1.0000, test acc 0.6033, test avg loss 2.459856, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 82] train avg loss 0.000000, train acc1.0000, test acc 0.6000, test avg loss 2.470671, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 83] train avg loss 0.000000, train acc1.0000, test acc 0.6000, test avg loss 2.484235, throughput 2.39K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 84] train avg loss 0.000000, train acc1.0000, test acc 0.6067, test avg loss 2.496064, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 85] train avg loss 0.000000, train acc1.0000, test acc 0.6067, test avg loss 2.508892, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 86] train avg loss 0.000000, train acc1.0000, test acc 0.6067, test avg loss 2.523564, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 87] train avg loss 0.000000, train acc1.0000, test acc 0.6067, test avg loss 2.535312, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 88] train avg loss 0.000000, train acc1.0000, test acc 0.6067, test avg loss 2.549475, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 89] train avg loss 0.000000, train acc1.0000, test acc 0.6067, test avg loss 2.562915, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 90] train avg loss 0.000000, train acc1.0000, test acc 0.6067, test avg loss 2.573829, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 91] train avg loss 0.000000, train acc1.0000, test acc 0.6067, test avg loss 2.587216, throughput 2.38K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 92] train avg loss 0.000000, train acc1.0000, test acc 0.6067, test avg loss 2.601103, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 93] train avg loss 0.000000, train acc1.0000, test acc 0.6067, test avg loss 2.614531, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 94] train avg loss 0.000000, train acc1.0000, test acc 0.6067, test avg loss 2.628261, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 95] train avg loss 0.000000, train acc1.0000, test acc 0.6033, test avg loss 2.643106, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 96] train avg loss 0.000000, train acc1.0000, test acc 0.6033, test avg loss 2.658240, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 97] train avg loss 0.000000, train acc1.0000, test acc 0.6033, test avg loss 2.672807, throughput 2.48K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 98] train avg loss 0.000000, train acc1.0000, test acc 0.6000, test avg loss 2.685464, throughput 2.39K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 99] train avg loss 0.000000, train acc1.0000, test acc 0.6000, test avg loss 2.698489, throughput 2.48K wps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4nm6PrkkWnC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64422352-61d4-46df-a717-3cbc858bf4ae"
      },
      "source": [
        "#pre-trained model performance in kitchen appliance domain\n",
        "def train(net, context, epochs):\n",
        "    trainer = gluon.Trainer(net.collect_params(), 'ftml',\n",
        "                            {'learning_rate': learning_rate})\n",
        "    loss = gluon.loss.SigmoidBCELoss()\n",
        "\n",
        "    parameters = net.collect_params().values()\n",
        "\n",
        "    # Training/Testing\n",
        "    for epoch in range(epochs):\n",
        "        # Epoch training stats\n",
        "        start_epoch_time = time.time()\n",
        "        epoch_L = 0.0\n",
        "        epoch_sent_num = 0\n",
        "        epoch_wc = 0\n",
        "        # Log interval training stats\n",
        "        start_log_interval_time = time.time()\n",
        "        log_interval_wc = 0\n",
        "        log_interval_sent_num = 0\n",
        "        log_interval_L = 0.0\n",
        "\n",
        "        for i, ((data, length), label) in enumerate(train_k_dataloader):\n",
        "            L = 0\n",
        "            wc = length.sum().asscalar()\n",
        "            log_interval_wc += wc\n",
        "            epoch_wc += wc\n",
        "            log_interval_sent_num += data.shape[1]\n",
        "            epoch_sent_num += data.shape[1]\n",
        "            with autograd.record():\n",
        "                output = net(data.as_in_context(context).T,\n",
        "                             length.as_in_context(context)\n",
        "                                   .astype(np.float32))\n",
        "                L = L + loss(output, label.as_in_context(context)).mean()\n",
        "            L.backward()\n",
        "            # Clip gradient\n",
        "            if grad_clip:\n",
        "                gluon.utils.clip_global_norm(\n",
        "                    [p.grad(context) for p in parameters],\n",
        "                    grad_clip)\n",
        "            # Update parameter\n",
        "            trainer.step(1)\n",
        "            log_interval_L += L.asscalar()\n",
        "            epoch_L += L.asscalar()\n",
        "            if (i + 1) % log_interval == 0:\n",
        "                print(\n",
        "                    '[Epoch {} Batch {}/{}] elapsed {:.2f} s, '\n",
        "                    'avg loss {:.6f}, throughput {:.2f}K wps'.format(\n",
        "                        epoch, i + 1, len(train_e_dataloader),\n",
        "                        time.time() - start_log_interval_time,\n",
        "                        log_interval_L / log_interval_sent_num, log_interval_wc\n",
        "                        / 1000 / (time.time() - start_log_interval_time)))\n",
        "                # Clear log interval training stats\n",
        "                start_log_interval_time = time.time()\n",
        "                log_interval_wc = 0\n",
        "                log_interval_sent_num = 0\n",
        "                log_interval_L = 0\n",
        "        end_epoch_time = time.time()\n",
        "        train_avg_L, train_acc = evaluate(net, train_k_dataloader, context)\n",
        "        test_avg_L, test_acc = evaluate(net, test_k_dataloader, context)\n",
        "        print('[Epoch {}] train avg loss {:.6f}, train acc{:.4f}, test acc {:.4f}, '\n",
        "              'test avg loss {:.6f}, throughput {:.2f}K wps'.format(\n",
        "                  epoch, epoch_L / epoch_sent_num, train_acc, test_acc, test_avg_L,\n",
        "                  epoch_wc / 1000 / (end_epoch_time - start_epoch_time)))\n",
        "        \n",
        "\n",
        "history4 = train(net, context, epochs)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 0] train avg loss 0.008003, train acc0.5894, test acc 0.0000, test avg loss 0.860046, throughput 2.74K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 1] train avg loss 0.005901, train acc0.9147, test acc 0.5633, test avg loss 0.681947, throughput 2.75K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 2] train avg loss 0.002428, train acc0.9753, test acc 0.6233, test avg loss 0.695118, throughput 2.73K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 3] train avg loss 0.000996, train acc0.9853, test acc 0.5833, test avg loss 1.403840, throughput 2.52K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 4] train avg loss 0.000585, train acc0.9959, test acc 0.6600, test avg loss 1.167990, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 5] train avg loss 0.000276, train acc0.9971, test acc 0.6167, test avg loss 1.871773, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 6] train avg loss 0.000149, train acc0.9982, test acc 0.6867, test avg loss 1.865234, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 7] train avg loss 0.000097, train acc0.9994, test acc 0.6900, test avg loss 2.213048, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 8] train avg loss 0.000836, train acc0.9918, test acc 0.5767, test avg loss 1.124154, throughput 2.42K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 9] train avg loss 0.000453, train acc0.9994, test acc 0.6200, test avg loss 1.409485, throughput 2.42K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 10] train avg loss 0.000128, train acc1.0000, test acc 0.6167, test avg loss 1.875562, throughput 2.42K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 11] train avg loss 0.000072, train acc1.0000, test acc 0.6067, test avg loss 2.167093, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 12] train avg loss 0.000051, train acc1.0000, test acc 0.6467, test avg loss 2.125770, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 13] train avg loss 0.000034, train acc1.0000, test acc 0.6400, test avg loss 2.294568, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 14] train avg loss 0.000027, train acc1.0000, test acc 0.6400, test avg loss 2.395357, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 15] train avg loss 0.000021, train acc1.0000, test acc 0.6367, test avg loss 2.492338, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 16] train avg loss 0.000018, train acc1.0000, test acc 0.6333, test avg loss 2.592868, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 17] train avg loss 0.000015, train acc1.0000, test acc 0.6300, test avg loss 2.682752, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 18] train avg loss 0.000013, train acc1.0000, test acc 0.6200, test avg loss 2.798287, throughput 2.32K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 19] train avg loss 0.000019, train acc1.0000, test acc 0.6167, test avg loss 2.927143, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 20] train avg loss 0.000009, train acc1.0000, test acc 0.6167, test avg loss 2.964879, throughput 2.42K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 21] train avg loss 0.000008, train acc1.0000, test acc 0.6200, test avg loss 3.037181, throughput 2.42K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 22] train avg loss 0.000008, train acc1.0000, test acc 0.6200, test avg loss 3.117931, throughput 2.41K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 23] train avg loss 0.000006, train acc1.0000, test acc 0.6267, test avg loss 3.138979, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 24] train avg loss 0.000006, train acc1.0000, test acc 0.6300, test avg loss 3.191042, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 25] train avg loss 0.000005, train acc1.0000, test acc 0.6267, test avg loss 3.237632, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 26] train avg loss 0.000005, train acc1.0000, test acc 0.6300, test avg loss 3.278249, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 27] train avg loss 0.000005, train acc1.0000, test acc 0.6300, test avg loss 3.316015, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 28] train avg loss 0.000004, train acc1.0000, test acc 0.6233, test avg loss 3.381542, throughput 2.42K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 29] train avg loss 0.000004, train acc1.0000, test acc 0.6233, test avg loss 3.417396, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 30] train avg loss 0.000003, train acc1.0000, test acc 0.6233, test avg loss 3.459574, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 31] train avg loss 0.000003, train acc1.0000, test acc 0.6233, test avg loss 3.510957, throughput 2.42K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 32] train avg loss 0.000003, train acc1.0000, test acc 0.6333, test avg loss 3.467904, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 33] train avg loss 0.000003, train acc1.0000, test acc 0.6300, test avg loss 3.530335, throughput 2.42K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 34] train avg loss 0.000002, train acc1.0000, test acc 0.6300, test avg loss 3.565070, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 35] train avg loss 0.000002, train acc1.0000, test acc 0.6267, test avg loss 3.608408, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 36] train avg loss 0.000002, train acc1.0000, test acc 0.6267, test avg loss 3.643916, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 37] train avg loss 0.000002, train acc1.0000, test acc 0.6267, test avg loss 3.689105, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 38] train avg loss 0.000002, train acc1.0000, test acc 0.6267, test avg loss 3.740601, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 39] train avg loss 0.000002, train acc1.0000, test acc 0.6267, test avg loss 3.780965, throughput 2.42K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 40] train avg loss 0.000002, train acc1.0000, test acc 0.6267, test avg loss 3.814189, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 41] train avg loss 0.000001, train acc1.0000, test acc 0.6233, test avg loss 3.845265, throughput 2.33K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 42] train avg loss 0.000001, train acc1.0000, test acc 0.6233, test avg loss 3.875916, throughput 2.42K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 43] train avg loss 0.000001, train acc1.0000, test acc 0.6167, test avg loss 3.978381, throughput 2.42K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 44] train avg loss 0.000001, train acc1.0000, test acc 0.6167, test avg loss 4.015011, throughput 2.42K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 45] train avg loss 0.000001, train acc1.0000, test acc 0.6167, test avg loss 4.039323, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 46] train avg loss 0.000001, train acc1.0000, test acc 0.6200, test avg loss 4.073164, throughput 2.42K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 47] train avg loss 0.000001, train acc1.0000, test acc 0.6200, test avg loss 4.108414, throughput 2.45K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 48] train avg loss 0.000001, train acc1.0000, test acc 0.6233, test avg loss 4.132567, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 49] train avg loss 0.000001, train acc1.0000, test acc 0.6200, test avg loss 4.169230, throughput 2.42K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 50] train avg loss 0.000001, train acc1.0000, test acc 0.6167, test avg loss 4.208105, throughput 2.41K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 51] train avg loss 0.000001, train acc1.0000, test acc 0.6200, test avg loss 4.239102, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 52] train avg loss 0.000001, train acc1.0000, test acc 0.6200, test avg loss 4.267020, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 53] train avg loss 0.000001, train acc1.0000, test acc 0.6200, test avg loss 4.294466, throughput 2.42K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 54] train avg loss 0.000001, train acc1.0000, test acc 0.6200, test avg loss 4.322541, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 55] train avg loss 0.000001, train acc1.0000, test acc 0.6200, test avg loss 4.351363, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 56] train avg loss 0.000001, train acc1.0000, test acc 0.6200, test avg loss 4.377229, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 57] train avg loss 0.000001, train acc1.0000, test acc 0.6200, test avg loss 4.316281, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 58] train avg loss 0.000001, train acc1.0000, test acc 0.6200, test avg loss 4.357360, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 59] train avg loss 0.000001, train acc1.0000, test acc 0.6200, test avg loss 4.403234, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 60] train avg loss 0.000001, train acc1.0000, test acc 0.6200, test avg loss 4.433633, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 61] train avg loss 0.000000, train acc1.0000, test acc 0.6200, test avg loss 4.460817, throughput 2.45K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 62] train avg loss 0.000000, train acc1.0000, test acc 0.6200, test avg loss 4.483887, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 63] train avg loss 0.000000, train acc1.0000, test acc 0.6233, test avg loss 4.509244, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 64] train avg loss 0.000000, train acc1.0000, test acc 0.6233, test avg loss 4.533027, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 65] train avg loss 0.000000, train acc1.0000, test acc 0.6233, test avg loss 4.554244, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 66] train avg loss 0.000000, train acc1.0000, test acc 0.6200, test avg loss 4.582509, throughput 2.40K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 67] train avg loss 0.000000, train acc1.0000, test acc 0.6200, test avg loss 4.606186, throughput 2.45K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 68] train avg loss 0.000000, train acc1.0000, test acc 0.6200, test avg loss 4.628855, throughput 2.45K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 69] train avg loss 0.000000, train acc1.0000, test acc 0.6200, test avg loss 4.652600, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 70] train avg loss 0.000000, train acc1.0000, test acc 0.6200, test avg loss 4.679560, throughput 2.45K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 71] train avg loss 0.000000, train acc1.0000, test acc 0.6200, test avg loss 4.704584, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 72] train avg loss 0.000000, train acc1.0000, test acc 0.6200, test avg loss 4.726687, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 73] train avg loss 0.000000, train acc1.0000, test acc 0.6167, test avg loss 4.756328, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 74] train avg loss 0.000000, train acc1.0000, test acc 0.6167, test avg loss 4.778122, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 75] train avg loss 0.000000, train acc1.0000, test acc 0.6167, test avg loss 4.827739, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 76] train avg loss 0.000000, train acc1.0000, test acc 0.6167, test avg loss 4.844528, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 77] train avg loss 0.000000, train acc1.0000, test acc 0.6167, test avg loss 4.865928, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 78] train avg loss 0.000000, train acc1.0000, test acc 0.6167, test avg loss 4.890222, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 79] train avg loss 0.000000, train acc1.0000, test acc 0.6167, test avg loss 4.906204, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 80] train avg loss 0.000000, train acc1.0000, test acc 0.6167, test avg loss 4.925705, throughput 2.42K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 81] train avg loss 0.000000, train acc1.0000, test acc 0.6167, test avg loss 4.944297, throughput 2.33K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 82] train avg loss 0.000000, train acc1.0000, test acc 0.6167, test avg loss 4.967347, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 83] train avg loss 0.000000, train acc1.0000, test acc 0.6167, test avg loss 4.986020, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 84] train avg loss 0.000000, train acc1.0000, test acc 0.6167, test avg loss 5.005405, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 85] train avg loss 0.000000, train acc1.0000, test acc 0.6167, test avg loss 5.019404, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 86] train avg loss 0.000000, train acc1.0000, test acc 0.6167, test avg loss 5.043427, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 87] train avg loss 0.000000, train acc1.0000, test acc 0.6167, test avg loss 5.060795, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 88] train avg loss 0.000000, train acc1.0000, test acc 0.6200, test avg loss 5.080776, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 89] train avg loss 0.000000, train acc1.0000, test acc 0.6200, test avg loss 5.096053, throughput 2.32K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 90] train avg loss 0.000000, train acc1.0000, test acc 0.6233, test avg loss 5.116753, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 91] train avg loss 0.000000, train acc1.0000, test acc 0.6233, test avg loss 5.130937, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 92] train avg loss 0.000000, train acc1.0000, test acc 0.6233, test avg loss 5.152993, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 93] train avg loss 0.000000, train acc1.0000, test acc 0.6233, test avg loss 5.169025, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 94] train avg loss 0.000000, train acc1.0000, test acc 0.6200, test avg loss 5.225500, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 95] train avg loss 0.000000, train acc1.0000, test acc 0.6200, test avg loss 5.254909, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 96] train avg loss 0.000000, train acc1.0000, test acc 0.6167, test avg loss 5.305970, throughput 2.44K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 97] train avg loss 0.000000, train acc1.0000, test acc 0.6167, test avg loss 5.322645, throughput 2.33K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 98] train avg loss 0.000000, train acc1.0000, test acc 0.6167, test avg loss 5.344398, throughput 2.43K wps\n",
            "Begin Testing...\n",
            "Begin Testing...\n",
            "[Epoch 99] train avg loss 0.000000, train acc1.0000, test acc 0.6167, test avg loss 5.362122, throughput 2.44K wps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3Xu5YkgkW96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhAQbFr8BmPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RJSQ_pZtMNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    }
  ]
}